{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature_selection+regression_modeling.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFFmpLBcXU45",
        "colab_type": "text"
      },
      "source": [
        "# Importing required  packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAfFUgfnXU46",
        "colab_type": "code",
        "outputId": "2ae12f00-99f1-4a8c-a8f8-dc21b2df34e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        }
      },
      "source": [
        "import pandas as pd\n",
        "from pandas.api.types import is_string_dtype\n",
        "from pandas.api.types import is_numeric_dtype\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression, RidgeClassifier\n",
        "from time import time\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score,mean_squared_log_error,r2_score\n",
        "from sklearn.model_selection import KFold ,cross_validate, cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, LeaveOneOut, cross_val_score, ParameterGrid\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.metrics import confusion_matrix, mean_squared_error, mean_absolute_error\n",
        "from time import time\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "!pip install catboost\n",
        "from catboost import  CatBoostRegressor\n",
        "\n",
        "\n",
        "# from keras.layers import Dense,Dropout\n",
        "# from keras import Sequential"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/ed/7d3b3ccfe8365ca69a5aa9f6855a11ea922d421801d6fbbcd071ac5a1b5e/catboost-0.15.2-cp36-none-manylinux1_x86_64.whl (61.2MB)\n",
            "\u001b[K     |████████████████████████████████| 61.2MB 511kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.16.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.0.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.12.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (3.6.1)\n",
            "Requirement already satisfied: pandas>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from catboost) (0.24.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (2018.9)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: decorator>=4.0.6 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (4.4.0)\n",
            "Requirement already satisfied: nbformat>=4.2 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (4.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (2.21.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (41.0.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly->catboost) (4.5.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly->catboost) (2.6.0)\n",
            "Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly->catboost) (4.3.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly->catboost) (0.2.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->plotly->catboost) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->plotly->catboost) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->plotly->catboost) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->plotly->catboost) (2019.6.16)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcVj1KnaXU49",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "uPLGOxo8XU4-",
        "colab_type": "code",
        "outputId": "f687b14a-dce2-438e-c547-39a1cc9a1d51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data_df=pd.read_csv(\"https://raw.githubusercontent.com/Kadri314/cadmium_data_science/master/data.csv\")\n",
        "print(data_df.columns)\n",
        "print(data_df.shape)\n",
        "print(data_df.info()) # we can notice from this that: type5industry 30 non-null float64 has one null value\n",
        "data_df.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Spring', 'aquifer', 'Cd_con', 'logged_cd', 'Type1industry',\n",
            "       'Type2industry', 'type3industry', 'type4industry', 'type5industry',\n",
            "       'type6industry', 'type7industry', 'type8industry', 'type9industry',\n",
            "       'Total_industry', 'MSWdumps', 'Multipledumps', 'Total_dump',\n",
            "       'burningdump ', 'NoBurningdump', 'Operational', 'Non_operational',\n",
            "       'Type1agri', 'Type2agri', 'type3agri', 'type4agri', 'type5agri',\n",
            "       'type6agri', 'type7agri', 'type8agri', 'type9agri', 'type10agri',\n",
            "       'type11agri', 'type12agri', 'type13agri', 'type14agri', 'type15agri',\n",
            "       'Total_agri', 'Mean_disindustry', 'Median_disindustry',\n",
            "       'Min_disindustry', 'Max_disindustry', 'Mean_yrs', 'Median_yrs',\n",
            "       'Min_yrs', 'Max_yrs', 'Mean_volume', 'Median_volume', 'Min_volume',\n",
            "       'Max_volume', 'Mean_area', 'Median_area', 'Min_area', 'Max_area',\n",
            "       'Mean_distdump', 'Median_distdump', 'Min_distdump', 'Max_distdump',\n",
            "       'Mean_areaagri', 'Median_areaagri', 'Min_areaagri', 'Max_areaagri',\n",
            "       'Mean_distagri', 'Median_distagri', 'Min_distagri', 'Max_distagri',\n",
            "       'Distance_Zouk', 'Slope', 'Precipitation', 'Traffic', 'SlopeInd'],\n",
            "      dtype='object')\n",
            "(31, 70)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 31 entries, 0 to 30\n",
            "Data columns (total 70 columns):\n",
            "Spring                31 non-null object\n",
            "aquifer               31 non-null object\n",
            "Cd_con                31 non-null float64\n",
            "logged_cd             31 non-null float64\n",
            "Type1industry         31 non-null int64\n",
            "Type2industry         31 non-null int64\n",
            "type3industry         31 non-null int64\n",
            "type4industry         31 non-null int64\n",
            "type5industry         30 non-null float64\n",
            "type6industry         31 non-null int64\n",
            "type7industry         31 non-null int64\n",
            "type8industry         31 non-null int64\n",
            "type9industry         31 non-null int64\n",
            "Total_industry        31 non-null int64\n",
            "MSWdumps              31 non-null int64\n",
            "Multipledumps         31 non-null int64\n",
            "Total_dump            31 non-null int64\n",
            "burningdump           31 non-null int64\n",
            "NoBurningdump         31 non-null int64\n",
            "Operational           31 non-null int64\n",
            "Non_operational       31 non-null int64\n",
            "Type1agri             31 non-null int64\n",
            "Type2agri             31 non-null int64\n",
            "type3agri             31 non-null int64\n",
            "type4agri             31 non-null int64\n",
            "type5agri             31 non-null int64\n",
            "type6agri             31 non-null int64\n",
            "type7agri             31 non-null int64\n",
            "type8agri             31 non-null int64\n",
            "type9agri             31 non-null int64\n",
            "type10agri            31 non-null int64\n",
            "type11agri            31 non-null int64\n",
            "type12agri            31 non-null int64\n",
            "type13agri            31 non-null int64\n",
            "type14agri            31 non-null int64\n",
            "type15agri            31 non-null int64\n",
            "Total_agri            31 non-null int64\n",
            "Mean_disindustry      31 non-null float64\n",
            "Median_disindustry    31 non-null float64\n",
            "Min_disindustry       31 non-null float64\n",
            "Max_disindustry       31 non-null float64\n",
            "Mean_yrs              31 non-null float64\n",
            "Median_yrs            31 non-null float64\n",
            "Min_yrs               31 non-null int64\n",
            "Max_yrs               31 non-null int64\n",
            "Mean_volume           31 non-null float64\n",
            "Median_volume         31 non-null int64\n",
            "Min_volume            31 non-null float64\n",
            "Max_volume            31 non-null int64\n",
            "Mean_area             31 non-null float64\n",
            "Median_area           31 non-null int64\n",
            "Min_area              31 non-null int64\n",
            "Max_area              31 non-null int64\n",
            "Mean_distdump         31 non-null float64\n",
            "Median_distdump       31 non-null float64\n",
            "Min_distdump          31 non-null float64\n",
            "Max_distdump          31 non-null float64\n",
            "Mean_areaagri         31 non-null float64\n",
            "Median_areaagri       31 non-null float64\n",
            "Min_areaagri          31 non-null int64\n",
            "Max_areaagri          31 non-null int64\n",
            "Mean_distagri         31 non-null float64\n",
            "Median_distagri       31 non-null float64\n",
            "Min_distagri          31 non-null float64\n",
            "Max_distagri          31 non-null float64\n",
            "Distance_Zouk         31 non-null float64\n",
            "Slope                 31 non-null float64\n",
            "Precipitation         31 non-null int64\n",
            "Traffic               31 non-null int64\n",
            "SlopeInd              31 non-null float64\n",
            "dtypes: float64(25), int64(43), object(2)\n",
            "memory usage: 17.0+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spring</th>\n",
              "      <th>aquifer</th>\n",
              "      <th>Cd_con</th>\n",
              "      <th>logged_cd</th>\n",
              "      <th>Type1industry</th>\n",
              "      <th>Type2industry</th>\n",
              "      <th>type3industry</th>\n",
              "      <th>type4industry</th>\n",
              "      <th>type5industry</th>\n",
              "      <th>type6industry</th>\n",
              "      <th>type7industry</th>\n",
              "      <th>type8industry</th>\n",
              "      <th>type9industry</th>\n",
              "      <th>Total_industry</th>\n",
              "      <th>MSWdumps</th>\n",
              "      <th>Multipledumps</th>\n",
              "      <th>Total_dump</th>\n",
              "      <th>burningdump</th>\n",
              "      <th>NoBurningdump</th>\n",
              "      <th>Operational</th>\n",
              "      <th>Non_operational</th>\n",
              "      <th>Type1agri</th>\n",
              "      <th>Type2agri</th>\n",
              "      <th>type3agri</th>\n",
              "      <th>type4agri</th>\n",
              "      <th>type5agri</th>\n",
              "      <th>type6agri</th>\n",
              "      <th>type7agri</th>\n",
              "      <th>type8agri</th>\n",
              "      <th>type9agri</th>\n",
              "      <th>type10agri</th>\n",
              "      <th>type11agri</th>\n",
              "      <th>type12agri</th>\n",
              "      <th>type13agri</th>\n",
              "      <th>type14agri</th>\n",
              "      <th>type15agri</th>\n",
              "      <th>Total_agri</th>\n",
              "      <th>Mean_disindustry</th>\n",
              "      <th>Median_disindustry</th>\n",
              "      <th>Min_disindustry</th>\n",
              "      <th>Max_disindustry</th>\n",
              "      <th>Mean_yrs</th>\n",
              "      <th>Median_yrs</th>\n",
              "      <th>Min_yrs</th>\n",
              "      <th>Max_yrs</th>\n",
              "      <th>Mean_volume</th>\n",
              "      <th>Median_volume</th>\n",
              "      <th>Min_volume</th>\n",
              "      <th>Max_volume</th>\n",
              "      <th>Mean_area</th>\n",
              "      <th>Median_area</th>\n",
              "      <th>Min_area</th>\n",
              "      <th>Max_area</th>\n",
              "      <th>Mean_distdump</th>\n",
              "      <th>Median_distdump</th>\n",
              "      <th>Min_distdump</th>\n",
              "      <th>Max_distdump</th>\n",
              "      <th>Mean_areaagri</th>\n",
              "      <th>Median_areaagri</th>\n",
              "      <th>Min_areaagri</th>\n",
              "      <th>Max_areaagri</th>\n",
              "      <th>Mean_distagri</th>\n",
              "      <th>Median_distagri</th>\n",
              "      <th>Min_distagri</th>\n",
              "      <th>Max_distagri</th>\n",
              "      <th>Distance_Zouk</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Precipitation</th>\n",
              "      <th>Traffic</th>\n",
              "      <th>SlopeInd</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ras el haref</td>\n",
              "      <td>27b</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>27</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>746</td>\n",
              "      <td>342</td>\n",
              "      <td>65</td>\n",
              "      <td>397</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>81</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>45</td>\n",
              "      <td>1781</td>\n",
              "      <td>7468.10</td>\n",
              "      <td>6974.81</td>\n",
              "      <td>1717.59</td>\n",
              "      <td>10925.57</td>\n",
              "      <td>6.67</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>996.88</td>\n",
              "      <td>200</td>\n",
              "      <td>10.0</td>\n",
              "      <td>5100</td>\n",
              "      <td>1029.17</td>\n",
              "      <td>300</td>\n",
              "      <td>20</td>\n",
              "      <td>5100</td>\n",
              "      <td>8394.92</td>\n",
              "      <td>7768.15</td>\n",
              "      <td>3330.45</td>\n",
              "      <td>17487.87</td>\n",
              "      <td>22754.45</td>\n",
              "      <td>5146.0</td>\n",
              "      <td>236</td>\n",
              "      <td>1965571</td>\n",
              "      <td>10768.59</td>\n",
              "      <td>9246.53</td>\n",
              "      <td>322.76</td>\n",
              "      <td>24805.02</td>\n",
              "      <td>36.7</td>\n",
              "      <td>-0.92</td>\n",
              "      <td>1200</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ain Jrain</td>\n",
              "      <td>28</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>1317</td>\n",
              "      <td>963</td>\n",
              "      <td>122</td>\n",
              "      <td>952</td>\n",
              "      <td>51</td>\n",
              "      <td>5</td>\n",
              "      <td>106</td>\n",
              "      <td>221</td>\n",
              "      <td>47</td>\n",
              "      <td>13</td>\n",
              "      <td>91</td>\n",
              "      <td>3980</td>\n",
              "      <td>16872.43</td>\n",
              "      <td>16872.43</td>\n",
              "      <td>16872.43</td>\n",
              "      <td>16872.43</td>\n",
              "      <td>10.50</td>\n",
              "      <td>10.5</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>1250.00</td>\n",
              "      <td>1250</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1500</td>\n",
              "      <td>875.00</td>\n",
              "      <td>875</td>\n",
              "      <td>750</td>\n",
              "      <td>1000</td>\n",
              "      <td>18669.39</td>\n",
              "      <td>18669.39</td>\n",
              "      <td>5962.25</td>\n",
              "      <td>31376.52</td>\n",
              "      <td>24059.80</td>\n",
              "      <td>4285.5</td>\n",
              "      <td>91</td>\n",
              "      <td>3957842</td>\n",
              "      <td>33258.78</td>\n",
              "      <td>36155.12</td>\n",
              "      <td>203.77</td>\n",
              "      <td>58814.80</td>\n",
              "      <td>30.7</td>\n",
              "      <td>-0.69</td>\n",
              "      <td>1500</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.67</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Spring aquifer  Cd_con  ...  Precipitation  Traffic  SlopeInd\n",
              "0  ras el haref     27b     1.0  ...           1200        0     -0.90\n",
              "1     Ain Jrain      28     1.0  ...           1500        0     -0.67\n",
              "\n",
              "[2 rows x 70 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2j7zrpnGXU5C",
        "colab_type": "code",
        "outputId": "253bd4b8-49bc-46dd-9bfd-12b67c7fc1b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        }
      },
      "source": [
        "#checking in which sample is type5industry has the value null\n",
        "data_df[pd.isnull(data_df).any(axis=1)] # yes indeed type5industry is null with sample number 13"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spring</th>\n",
              "      <th>aquifer</th>\n",
              "      <th>Cd_con</th>\n",
              "      <th>logged_cd</th>\n",
              "      <th>Type1industry</th>\n",
              "      <th>Type2industry</th>\n",
              "      <th>type3industry</th>\n",
              "      <th>type4industry</th>\n",
              "      <th>type5industry</th>\n",
              "      <th>type6industry</th>\n",
              "      <th>type7industry</th>\n",
              "      <th>type8industry</th>\n",
              "      <th>type9industry</th>\n",
              "      <th>Total_industry</th>\n",
              "      <th>MSWdumps</th>\n",
              "      <th>Multipledumps</th>\n",
              "      <th>Total_dump</th>\n",
              "      <th>burningdump</th>\n",
              "      <th>NoBurningdump</th>\n",
              "      <th>Operational</th>\n",
              "      <th>Non_operational</th>\n",
              "      <th>Type1agri</th>\n",
              "      <th>Type2agri</th>\n",
              "      <th>type3agri</th>\n",
              "      <th>type4agri</th>\n",
              "      <th>type5agri</th>\n",
              "      <th>type6agri</th>\n",
              "      <th>type7agri</th>\n",
              "      <th>type8agri</th>\n",
              "      <th>type9agri</th>\n",
              "      <th>type10agri</th>\n",
              "      <th>type11agri</th>\n",
              "      <th>type12agri</th>\n",
              "      <th>type13agri</th>\n",
              "      <th>type14agri</th>\n",
              "      <th>type15agri</th>\n",
              "      <th>Total_agri</th>\n",
              "      <th>Mean_disindustry</th>\n",
              "      <th>Median_disindustry</th>\n",
              "      <th>Min_disindustry</th>\n",
              "      <th>Max_disindustry</th>\n",
              "      <th>Mean_yrs</th>\n",
              "      <th>Median_yrs</th>\n",
              "      <th>Min_yrs</th>\n",
              "      <th>Max_yrs</th>\n",
              "      <th>Mean_volume</th>\n",
              "      <th>Median_volume</th>\n",
              "      <th>Min_volume</th>\n",
              "      <th>Max_volume</th>\n",
              "      <th>Mean_area</th>\n",
              "      <th>Median_area</th>\n",
              "      <th>Min_area</th>\n",
              "      <th>Max_area</th>\n",
              "      <th>Mean_distdump</th>\n",
              "      <th>Median_distdump</th>\n",
              "      <th>Min_distdump</th>\n",
              "      <th>Max_distdump</th>\n",
              "      <th>Mean_areaagri</th>\n",
              "      <th>Median_areaagri</th>\n",
              "      <th>Min_areaagri</th>\n",
              "      <th>Max_areaagri</th>\n",
              "      <th>Mean_distagri</th>\n",
              "      <th>Median_distagri</th>\n",
              "      <th>Min_distagri</th>\n",
              "      <th>Max_distagri</th>\n",
              "      <th>Distance_Zouk</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Precipitation</th>\n",
              "      <th>Traffic</th>\n",
              "      <th>SlopeInd</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Ain el saydeh</td>\n",
              "      <td>28</td>\n",
              "      <td>9.9445</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>35</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>35</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>1317</td>\n",
              "      <td>963</td>\n",
              "      <td>122</td>\n",
              "      <td>952</td>\n",
              "      <td>51</td>\n",
              "      <td>5</td>\n",
              "      <td>106</td>\n",
              "      <td>221</td>\n",
              "      <td>47</td>\n",
              "      <td>13</td>\n",
              "      <td>91</td>\n",
              "      <td>3980</td>\n",
              "      <td>8257.03</td>\n",
              "      <td>3506.59</td>\n",
              "      <td>2314.03</td>\n",
              "      <td>36288.37</td>\n",
              "      <td>5.18</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>2151.76</td>\n",
              "      <td>1000</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20000</td>\n",
              "      <td>1303.82</td>\n",
              "      <td>500</td>\n",
              "      <td>15</td>\n",
              "      <td>10000</td>\n",
              "      <td>12146.25</td>\n",
              "      <td>11446.22</td>\n",
              "      <td>2343.56</td>\n",
              "      <td>32374.55</td>\n",
              "      <td>24059.8</td>\n",
              "      <td>4285.5</td>\n",
              "      <td>91</td>\n",
              "      <td>3957842</td>\n",
              "      <td>16902.55</td>\n",
              "      <td>12080.35</td>\n",
              "      <td>112.02</td>\n",
              "      <td>48746.46</td>\n",
              "      <td>28.5</td>\n",
              "      <td>-1.15</td>\n",
              "      <td>1200</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Spring aquifer  Cd_con  ...  Precipitation  Traffic  SlopeInd\n",
              "13  Ain el saydeh      28  9.9445  ...           1200        1     -1.12\n",
              "\n",
              "[1 rows x 70 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkE8BrReXU5F",
        "colab_type": "code",
        "outputId": "d38738a4-226f-4411-ecc2-436eb824d4b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Replacing the value of type5industry with Nan value with 0 value as if the spring has 0 type5industry\n",
        "data_df['type5industry'].fillna(0, inplace=True)\n",
        "data_df[pd.isnull(data_df).any(axis=1)] # check if null value exist after replacing type5industry"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spring</th>\n",
              "      <th>aquifer</th>\n",
              "      <th>Cd_con</th>\n",
              "      <th>logged_cd</th>\n",
              "      <th>Type1industry</th>\n",
              "      <th>Type2industry</th>\n",
              "      <th>type3industry</th>\n",
              "      <th>type4industry</th>\n",
              "      <th>type5industry</th>\n",
              "      <th>type6industry</th>\n",
              "      <th>type7industry</th>\n",
              "      <th>type8industry</th>\n",
              "      <th>type9industry</th>\n",
              "      <th>Total_industry</th>\n",
              "      <th>MSWdumps</th>\n",
              "      <th>Multipledumps</th>\n",
              "      <th>Total_dump</th>\n",
              "      <th>burningdump</th>\n",
              "      <th>NoBurningdump</th>\n",
              "      <th>Operational</th>\n",
              "      <th>Non_operational</th>\n",
              "      <th>Type1agri</th>\n",
              "      <th>Type2agri</th>\n",
              "      <th>type3agri</th>\n",
              "      <th>type4agri</th>\n",
              "      <th>type5agri</th>\n",
              "      <th>type6agri</th>\n",
              "      <th>type7agri</th>\n",
              "      <th>type8agri</th>\n",
              "      <th>type9agri</th>\n",
              "      <th>type10agri</th>\n",
              "      <th>type11agri</th>\n",
              "      <th>type12agri</th>\n",
              "      <th>type13agri</th>\n",
              "      <th>type14agri</th>\n",
              "      <th>type15agri</th>\n",
              "      <th>Total_agri</th>\n",
              "      <th>Mean_disindustry</th>\n",
              "      <th>Median_disindustry</th>\n",
              "      <th>Min_disindustry</th>\n",
              "      <th>Max_disindustry</th>\n",
              "      <th>Mean_yrs</th>\n",
              "      <th>Median_yrs</th>\n",
              "      <th>Min_yrs</th>\n",
              "      <th>Max_yrs</th>\n",
              "      <th>Mean_volume</th>\n",
              "      <th>Median_volume</th>\n",
              "      <th>Min_volume</th>\n",
              "      <th>Max_volume</th>\n",
              "      <th>Mean_area</th>\n",
              "      <th>Median_area</th>\n",
              "      <th>Min_area</th>\n",
              "      <th>Max_area</th>\n",
              "      <th>Mean_distdump</th>\n",
              "      <th>Median_distdump</th>\n",
              "      <th>Min_distdump</th>\n",
              "      <th>Max_distdump</th>\n",
              "      <th>Mean_areaagri</th>\n",
              "      <th>Median_areaagri</th>\n",
              "      <th>Min_areaagri</th>\n",
              "      <th>Max_areaagri</th>\n",
              "      <th>Mean_distagri</th>\n",
              "      <th>Median_distagri</th>\n",
              "      <th>Min_distagri</th>\n",
              "      <th>Max_distagri</th>\n",
              "      <th>Distance_Zouk</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Precipitation</th>\n",
              "      <th>Traffic</th>\n",
              "      <th>SlopeInd</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Spring, aquifer, Cd_con, logged_cd, Type1industry, Type2industry, type3industry, type4industry, type5industry, type6industry, type7industry, type8industry, type9industry, Total_industry, MSWdumps, Multipledumps, Total_dump, burningdump , NoBurningdump, Operational, Non_operational, Type1agri, Type2agri, type3agri, type4agri, type5agri, type6agri, type7agri, type8agri, type9agri, type10agri, type11agri, type12agri, type13agri, type14agri, type15agri, Total_agri, Mean_disindustry, Median_disindustry, Min_disindustry, Max_disindustry, Mean_yrs, Median_yrs, Min_yrs, Max_yrs, Mean_volume, Median_volume, Min_volume, Max_volume, Mean_area, Median_area, Min_area, Max_area, Mean_distdump, Median_distdump, Min_distdump, Max_distdump, Mean_areaagri, Median_areaagri, Min_areaagri, Max_areaagri, Mean_distagri, Median_distagri, Min_distagri, Max_distagri, Distance_Zouk, Slope, Precipitation, Traffic, SlopeInd]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPS46Z9mXU5I",
        "colab_type": "code",
        "outputId": "d3740079-65a8-46cf-c3b1-d0fd60774042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Split the data into training and testin\n",
        "X=data_df[data_df.columns.difference(['Spring', 'aquifer', 'Cd_con', 'logged_cd'])]# to omit the columns:  'Spring', 'aquifer', 'Cd_con', 'logged_cd'\n",
        "y=data_df[\"Cd_con\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "X_train.reset_index(drop=True, inplace=True)\n",
        "X_test.reset_index(drop=True, inplace=True)\n",
        "y_train.reset_index(drop=True, inplace=True)\n",
        "y_test.reset_index(drop=True, inplace=True)\n",
        "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24, 66) (24,) (7, 66) (7,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "fBZmVCwlXU5M",
        "colab_type": "code",
        "outputId": "7c16cf33-9299-47a1-fe57-46bb28dc48cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "source": [
        "# standardize data\n",
        "scaler = preprocessing.StandardScaler().fit(X_train) # calculate the mean and std only on the training data \n",
        "print(scaler.mean_) #mean of each feature in   the training data\n",
        "print(scaler.var_ ) # variance of each feature in the training data\n",
        "X_train= scaler.transform(X_train) #standardize training data \n",
        "X_test= scaler.transform(X_test) # standardize testing data \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 3.70500000e+01  7.12500000e+00  4.10625000e+03  3.34359304e+06\n",
            "  2.58509692e+04  4.70753367e+04  2.51374667e+04  7.27291667e+03\n",
            "  1.65833333e+01  8.61711250e+02  2.29599937e+04  1.18658921e+04\n",
            "  1.97628717e+04  1.12936408e+04  1.26411167e+03  6.71583333e+00\n",
            "  5.03125000e+02  4.46772917e+03  9.80962042e+03  1.74521838e+04\n",
            "  9.98919458e+03  8.40000000e+02  4.52083333e+00  2.06500000e+02\n",
            "  1.19333333e+02  5.59781417e+03  2.03738333e+02  3.04114667e+03\n",
            "  3.19658333e+02  3.79166667e+00  2.16666667e+00  8.16666667e+00\n",
            "  2.08333333e+00  7.12500000e+00  1.25000000e+03 -9.32083333e-01\n",
            " -9.41250000e-01  3.23962500e+03  9.29166667e+00  1.47500000e+01\n",
            "  8.33333333e-01  3.27083333e+01  8.33333333e-01  2.64166667e+01\n",
            "  2.20833333e+00  1.04166667e+00  3.95833333e+00  9.15833333e+01\n",
            "  1.79791667e+02  3.62500000e+01  1.15000000e+01  7.37500000e+01\n",
            "  8.75000000e-01  1.04166667e+00  1.97500000e+01  7.50000000e-01\n",
            "  1.08400000e+03  2.91666667e-01  7.74000000e+02  2.54166667e+00\n",
            "  1.23875000e+02  4.00000000e+00  7.44000000e+02  2.54166667e+00\n",
            "  3.71666667e+01  5.41666667e-01]\n",
            "[2.32200000e+02 4.39427083e+01 1.45696484e+07 1.19441357e+12\n",
            " 3.03086307e+08 2.26030473e+08 2.37097967e+08 5.94470790e+07\n",
            " 7.21597222e+01 1.97205176e+05 6.39982812e+06 4.69927951e+07\n",
            " 7.13987015e+07 4.35145396e+07 4.88063691e+05 2.38587993e+01\n",
            " 8.88183594e+04 1.25313541e+05 5.12299460e+07 1.12535544e+08\n",
            " 3.99800317e+07 2.89225000e+05 2.62599826e+01 1.00730083e+05\n",
            " 2.73622222e+03 3.15836113e+07 1.38347675e+04 6.23420638e+06\n",
            " 3.04172852e+05 2.39149306e+01 1.80555556e+00 4.89722222e+01\n",
            " 2.74305556e+00 4.72760417e+01 5.00000000e+04 7.79914931e-02\n",
            " 7.42942708e-02 1.54484840e+06 6.02899306e+01 2.28687500e+02\n",
            " 6.38888889e-01 1.27539931e+02 8.05555556e-01 1.36326389e+02\n",
            " 4.08159722e+00 7.06597222e-01 4.78993056e+00 1.55090972e+03\n",
            " 5.10699826e+03 3.03937500e+02 3.76666667e+01 8.41187500e+02\n",
            " 1.76093750e+01 2.28993056e+00 7.67708333e+01 1.18750000e+00\n",
            " 1.62063583e+05 1.03993056e+00 9.81347500e+04 8.16493056e+00\n",
            " 6.66860938e+03 1.51666667e+01 1.12039333e+05 8.83159722e+00\n",
            " 4.65555556e+02 6.64930556e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYRVDYp3XU5P",
        "colab_type": "text"
      },
      "source": [
        "# Feature selection using PCA with one leave out corss validation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "q_MDKx4-XU5Q",
        "colab_type": "code",
        "outputId": "3f635374-be34-419f-8407-68979f50b54e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=5)\n",
        "x_new = pca.fit_transform(X_train)\n",
        "print(pca.explained_variance_ratio_)\n",
        "print(abs( pca.components_ )[0])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.3666501  0.20852002 0.14194531 0.07510119 0.04051139]\n",
            "[0.110126   0.14691323 0.15539648 0.12313377 0.18426324 0.11707882\n",
            " 0.17540863 0.16084202 0.07638356 0.15403769 0.08908131 0.11194244\n",
            " 0.00058791 0.13985707 0.1578536  0.01109195 0.0744213  0.1214613\n",
            " 0.06803092 0.05979708 0.10710727 0.10041889 0.00668684 0.02703321\n",
            " 0.11270335 0.01875749 0.05876492 0.0495241  0.03281463 0.0033526\n",
            " 0.17234572 0.15588363 0.09778839 0.15308102 0.04044659 0.00900464\n",
            " 0.00825382 0.160638   0.15524958 0.17345966 0.02736287 0.09672623\n",
            " 0.15212309 0.13518461 0.18157354 0.14707549 0.11577815 0.10927337\n",
            " 0.15654952 0.15635025 0.0804267  0.16183717 0.03838021 0.16557888\n",
            " 0.15287972 0.1657405  0.16196476 0.04870334 0.15991644 0.1325765\n",
            " 0.01259944 0.17160752 0.15708205 0.15869411 0.15048699 0.14737079]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qE-Pn-quXU5T",
        "colab_type": "code",
        "outputId": "7e9d6d46-1155-49f8-85da-20422ef7bc2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test=[100,90,200,10,1000,1]\n",
        "indices = np.argsort(test)[::-1]\n",
        "print(indices)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4 2 0 1 3 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Krk8R7VsXU5W",
        "colab_type": "text"
      },
      "source": [
        "we can see that PC1 explains 36%, PC2 20%, PC3 14%, PC4 7%, PC5=4%, PC6=3.6 % and so on .... \n",
        "<br/>I will be using only the first Principle component for feature selection process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "3FyIQPajXU5X",
        "colab_type": "code",
        "outputId": "6e2e7ca9-e539-4fc6-d21f-64e1b89327bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#I will pick only the top 10 features\n",
        "loo = LeaveOneOut()\n",
        "loo.get_n_splits(X_train)\n",
        "PCA_scores={} # key is the feature index, value is the score (total votes)\n",
        "for train_index, test_index in loo.split(X_train):\n",
        "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train_cross, X_test_cross = X_train[train_index,:], X_train[test_index,:]\n",
        "    y_train_cross, y_test_cross = y_train[train_index], y_train[test_index]\n",
        "    pca = PCA(n_components=1)\n",
        "    x_new = pca.fit_transform(X_train_cross)\n",
        "    indices=np.argsort(abs( pca.components_ )[0])[::-1][:4] # get the indices of the top 4 voted features in sorted order\n",
        "     # accumualte the vote scores for all cross validation \n",
        "    for index_feaure in indices:\n",
        "        if index_feaure in PCA_scores:\n",
        "            PCA_scores[index_feaure]= PCA_scores[index_feaure]+1\n",
        "        else:\n",
        "            PCA_scores[index_feaure]=1\n",
        "\n",
        "PCA_scores=dict(sorted(PCA_scores.items(), key=lambda x: x[1], reverse=True)) #sort by top voted\n",
        "print(PCA_scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{44: 22, 4: 22, 6: 16, 39: 13, 30: 7, 56: 6, 51: 4, 61: 2, 53: 2, 14: 1, 37: 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auzkqXslXU5a",
        "colab_type": "text"
      },
      "source": [
        "We can see that feature with index 44 has been voted to be top feature 22 times <br/>\n",
        "Feature with index 4 has been voted to be top feature 22 times and so on ...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "But1qA6UXU5b",
        "colab_type": "code",
        "outputId": "08b6a99f-6ae1-45a9-9f57-bab81d44c6a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "top_features_PCA=list(PCA_scores.keys())\n",
        "X.columns[top_features_PCA] #list top voted features by PCA"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Type2industry', 'Max_disindustry', 'Max_distdump', 'Total_industry',\n",
              "       'Multipledumps', 'type5agri', 'type15agri', 'type7industry',\n",
              "       'type3industry', 'Mean_volume', 'Total_agri'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN3OVI-NXU5e",
        "colab_type": "text"
      },
      "source": [
        "# Feature selection using Decision trees with one leave out corss validation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ff6o2cw0XU5f",
        "colab_type": "code",
        "outputId": "45592936-d8bb-41a7-b520-9adf6e345d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "\n",
        "DT_scores={} # key is the feature index, value is the score (total votes)\n",
        "loo = LeaveOneOut()\n",
        "loo.get_n_splits(X_train)\n",
        "for train_index, test_index in loo.split(X_train):\n",
        "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train_cross, X_test_cross = X_train[train_index,:], X_train[test_index,:]\n",
        "    y_train_cross, y_test_cross = y_train[train_index], y_train[test_index]\n",
        "    \n",
        "    forest = ExtraTreesRegressor(n_estimators=100,\n",
        "                              random_state=0)\n",
        "\n",
        "    forest.fit(X_train_cross, y_train_cross)\n",
        "    importances = forest.feature_importances_\n",
        "    indices = np.argsort(importances)[::-1][:4] # get the indices of the top 4 voted features in sorted order\n",
        "    # accumualte the vote scores for all cross validation \n",
        "    for index_feaure in indices:\n",
        "        if index_feaure in DT_scores:\n",
        "            DT_scores[index_feaure]= DT_scores[index_feaure]+1\n",
        "        else:\n",
        "            DT_scores[index_feaure]=1\n",
        "            \n",
        "DT_scores=dict(sorted(DT_scores.items(), key=lambda x: x[1], reverse=True)) #sort by top voted\n",
        "print(DT_scores)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{40: 24, 35: 17, 34: 15, 26: 10, 36: 10, 14: 4, 6: 3, 2: 2, 8: 2, 19: 2, 11: 1, 29: 1, 0: 1, 18: 1, 57: 1, 59: 1, 27: 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEvoj7T5XU5i",
        "colab_type": "text"
      },
      "source": [
        "We can see that feature with index 44 has been voted to be top feature 24 times <br/>\n",
        "Feature with index 35 has been voted to be top feature 17 times and so on ...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49cv7NP6XU5j",
        "colab_type": "code",
        "outputId": "7596d337-b842-4a25-f0b4-38cad6a20900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "print(\"Top features by decision trees: \")\n",
        "top_features_DT=list(DT_scores.keys())\n",
        "X.columns[top_features_DT] #list top voted features by decision trees"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top features by decision trees: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Traffic', 'Slope', 'Precipitation', 'Min_distagri', 'SlopeInd',\n",
              "       'Mean_volume', 'Max_distdump', 'Max_area', 'Max_yrs', 'Median_distagri',\n",
              "       'Mean_disindustry', 'Min_yrs', 'Distance_Zouk', 'Median_disindustry',\n",
              "       'type5industry', 'type6industry', 'Min_distdump'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CDqRrfhXU5o",
        "colab_type": "text"
      },
      "source": [
        "# Feature selection using univariate selection with one leave out corss validation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5ThTfE_XU5o",
        "colab_type": "code",
        "outputId": "77a26dcc-ad7b-4267-c2b5-719aa7244342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import f_regression\n",
        "\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "\n",
        "UV_scores={} # key is the feature index, value is the score (total votes)\n",
        "loo = LeaveOneOut()\n",
        "loo.get_n_splits(X_train)\n",
        "for train_index, test_index in loo.split(X_train):\n",
        "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train_cross, X_test_cross = X_train[train_index,:], X_train[test_index,:]\n",
        "    y_train_cross, y_test_cross = y_train[train_index], y_train[test_index]\n",
        "    \n",
        "    UV = SelectKBest(score_func=f_regression, k=10)\n",
        "\n",
        "    UV.fit(X_train_cross, y_train_cross)\n",
        "    importances = UV.scores_\n",
        "    indices = np.argsort(importances)[::-1][:4] # get the indices of the top 4 voted features in sorted order\n",
        "    # accumualte the vote scores for all cross validation \n",
        "    for index_feaure in indices:\n",
        "        if index_feaure in UV_scores:\n",
        "            UV_scores[index_feaure]= UV_scores[index_feaure]+1\n",
        "        else:\n",
        "            UV_scores[index_feaure]=1\n",
        "            \n",
        "UV_scores=dict(sorted(UV_scores.items(), key=lambda x: x[1], reverse=True)) #sort by top voted\n",
        "print(UV_scores)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{40: 24, 13: 23, 20: 22, 6: 12, 34: 7, 19: 3, 8: 2, 52: 1, 9: 1, 57: 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/univariate_selection.py:293: RuntimeWarning: invalid value encountered in sqrt\n",
            "  n_samples * X_means ** 2)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in greater\n",
            "  return (a < x) & (x < b)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in less\n",
            "  return (a < x) & (x < b)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:1892: RuntimeWarning: invalid value encountered in less_equal\n",
            "  cond2 = cond0 & (x <= _a)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySLhiBOLXU5t",
        "colab_type": "code",
        "outputId": "c769515c-4a68-453b-aa04-9ec5eca81333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "print(\"Top features by univariate selection: \")\n",
        "top_features_UV=list(UV_scores.keys())\n",
        "X.columns[top_features_UV] #list top voted features by decision trees"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top features by univariate selection: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Traffic', 'Mean_distdump', 'Median_distdump', 'Max_distdump',\n",
              "       'Precipitation', 'Median_distagri', 'Max_yrs', 'type3agri', 'Mean_area',\n",
              "       'type5industry'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm14q3hkXU5w",
        "colab_type": "text"
      },
      "source": [
        "# Feature selection using Recursive Feature Elimination with one leave out corss validation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJZGmQ_9XU5x",
        "colab_type": "code",
        "outputId": "d55a95d9-60b1-4db2-e349-488533e15322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# Feature Extraction with RFE\n",
        "from pandas import read_csv\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "RFE_scores={} # key is the feature index, value is the score (total votes)\n",
        "loo = LeaveOneOut()\n",
        "loo.get_n_splits(X_train)\n",
        "for train_index, test_index in loo.split(X_train):\n",
        "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train_cross, X_test_cross = X_train[train_index,:], X_train[test_index,:]\n",
        "    y_train_cross, y_test_cross = y_train[train_index], y_train[test_index]\n",
        "    \n",
        "        # feature extraction\n",
        "    model = LinearRegression()\n",
        "    rfe = RFE(model)\n",
        "    fit = rfe.fit(X_train_cross, y_train_cross)\n",
        "\n",
        "    # accumualte the vote scores for all cross validation \n",
        "    for feature_index in range(0,len(fit.ranking_)):\n",
        "        if feature_index in RFE_scores:\n",
        "            RFE_scores[feature_index]=RFE_scores[feature_index]+fit.ranking_[feature_index]\n",
        "        else:\n",
        "            RFE_scores[feature_index]=fit.ranking_[feature_index]\n",
        "            \n",
        "RFE_scores=dict(sorted(RFE_scores.items(), key=lambda x: x[1], reverse=False)) #sort by top voted\n",
        "print(RFE_scores)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{13: 24, 40: 24, 51: 24, 56: 24, 26: 28, 55: 28, 24: 34, 53: 39, 63: 43, 65: 43, 30: 48, 37: 48, 11: 51, 61: 59, 41: 60, 0: 67, 45: 71, 49: 80, 14: 82, 25: 86, 17: 87, 3: 88, 1: 92, 4: 99, 42: 100, 5: 105, 38: 114, 58: 116, 31: 120, 59: 122, 33: 130, 27: 136, 52: 138, 22: 143, 34: 150, 7: 157, 23: 165, 28: 172, 48: 230, 8: 231, 62: 237, 18: 254, 46: 265, 12: 281, 20: 294, 19: 298, 10: 308, 6: 312, 15: 341, 39: 361, 2: 417, 16: 447, 9: 451, 32: 451, 29: 464, 60: 478, 36: 491, 35: 501, 57: 523, 43: 532, 21: 562, 64: 565, 44: 598, 50: 643, 54: 645, 47: 671}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw_XDF-NXU53",
        "colab_type": "code",
        "outputId": "9c2c0086-ae17-43f5-a08b-dd7c18b5c7df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "# top 10 selected feature by RFE\n",
        "print(\"Top features by RFE: \")\n",
        "top_features_RFE=list(RFE_scores.keys())\n",
        "X.columns[top_features_RFE][:10] #list top voted features by decision trees"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top features by RFE: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Mean_distdump', 'Traffic', 'type15agri', 'type5agri', 'Min_distagri',\n",
              "       'type4industry', 'Min_areaagri', 'type3industry', 'type8industry',\n",
              "       'type9industry'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wKcigjlXU57",
        "colab_type": "code",
        "outputId": "4817bcc7-e99d-42fd-a546-57a7379b2438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#taking the intersection between all features_model\n",
        "set_a= list(set(top_features_RFE).intersection(set(top_features_UV)))\n",
        "set_b= list(set(set_a).intersection(set(top_features_DT)))\n",
        "set_c= list(set(set_b).intersection(set(top_features_PCA)))\n",
        "X.columns[set_c]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Max_distdump'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPvPQatWXU5-",
        "colab_type": "text"
      },
      "source": [
        "top selected feature(s) for the intersection between all models is only  'Max_distdump'. <br/>\n",
        "I will take the set of top 3 features from each model: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f--vUEFxXU5-",
        "colab_type": "code",
        "outputId": "a74878df-65fc-4c5f-925a-dab3ca67a1de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "top_features=set(top_features_UV[:2]+top_features_RFE[:2]+top_features_DT[:2]+top_features_PCA[:2])\n",
        "top_features=list(top_features)\n",
        "print(\"Top features:\")\n",
        "print(X.columns[top_features])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top features:\n",
            "Index(['Slope', 'Max_disindustry', 'Traffic', 'Type2industry',\n",
            "       'Mean_distdump'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_3it3VFXU6B",
        "colab_type": "code",
        "outputId": "b41fa61b-1953-496d-fbce-09ba17c83489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train=X_train[:,top_features]\n",
        "X_test=X_test[:,top_features]\n",
        "print(X_train.shape,X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24, 5) (7, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmnRVjqJXU6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define MAPE error function: \n",
        "def mean_absolute_percentage_error(y_true, y_pred): \n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU6Pni7WX2gE",
        "colab_type": "text"
      },
      "source": [
        "# Tuning hyper-parameters on the top selected features + modeling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEEQPcCTXU6L",
        "colab_type": "text"
      },
      "source": [
        "# SVM with polinomial kernal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1qN4G1jXU6L",
        "colab_type": "code",
        "outputId": "9d97f2ca-d743-4304-d625-777909512a6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "current=time()\n",
        "\n",
        " # gird of parameters for poly kernal\n",
        "tuned_parameters = [{'kernel': ['poly'], 'gamma': [1e-3,1e-6,1e-2,1e-1,1,10,100],'degree':[2,3,4,5,6,7],\n",
        "                     'C': [0.0001,0.01,0.1,0.5,1,3,5,10,1000]}]\n",
        "\n",
        "\n",
        "best_parameters=None\n",
        "top_mean_rmse_error=10000000\n",
        "top_mean_mse_error=10000000\n",
        "top_mean_mae_error=10000000\n",
        "top_mean_mape_error=10000000\n",
        "top_y_true=[]\n",
        "top_preds=[]\n",
        "\n",
        "print(\"# Tuning hyper-parameters\" )\n",
        "print()\n",
        "# Simulating grid search \n",
        "for g in ParameterGrid(tuned_parameters):\n",
        "    # for each possible combination in the grid\n",
        "    svm= SVR(**g)\n",
        "    mse_scores=[]\n",
        "    mae_scores=[]\n",
        "    rmse_scores=[]\n",
        "    mape_scores=[]\n",
        "    y_true=[]\n",
        "    preds=[]\n",
        "    # doing 1 leave out cross validation\n",
        "    loo = LeaveOneOut()\n",
        "    loo.get_n_splits(X_train)\n",
        "    for train_index, test_index in loo.split(X_train):\n",
        "        X_train_cross, X_test_cross = X_train[train_index,:], X_train[test_index,:]\n",
        "        y_train_cross, y_test_cross = y_train[train_index], y_train[test_index]\n",
        "        \n",
        "        svm.fit(X_train_cross,y_train_cross)\n",
        "        pred=svm.predict(X_test_cross)\n",
        "        \n",
        "        preds.append(pred)\n",
        "        y_true.append(y_test_cross.values[0])\n",
        "        \n",
        "        mse=mean_squared_error(y_test_cross,pred)\n",
        "        mae=mean_absolute_error(y_test_cross,pred)\n",
        "        mape=mean_absolute_percentage_error(y_test_cross,pred)\n",
        "        \n",
        "        mse_scores.append(mse)\n",
        "        mae_scores.append(mae)\n",
        "        rmse_scores.append(np.sqrt(mse))\n",
        "        mape_scores.append(mape)\n",
        "        \n",
        "    if np.mean(rmse_scores) < top_mean_rmse_error:\n",
        "        top_mean_mse_error=np.mean(mse_scores) \n",
        "        top_mean_mae_error=np.mean(mae_scores)\n",
        "        top_mean_rmse_error=np.mean(rmse_scores)\n",
        "        top_mean_mape_error=np.mean(mape_scores)\n",
        "        best_parameters=g\n",
        "        top_y_true=y_true\n",
        "        top_preds=preds\n",
        "    \n",
        "      \n",
        "print(\"It took \"+ str((time()-current)/60)+\" mins\")\n",
        "print(\"Best parameters for SVM with polynomial kernal:\")\n",
        "print(best_parameters)\n",
        "print(\"With mean score of MSE:\",top_mean_mse_error)\n",
        "print(\"With mean score of MAE:\",top_mean_mae_error)\n",
        "print(\"With mean score of RMSE:\",top_mean_rmse_error)\n",
        "# print(\"With mean score of MAPE:\",top_mean_mape_error)\n",
        "print(\"Cad concentration mean:\",np.mean(y_train))\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': top_y_true,\n",
        "     'lst2Title': np.reshape(np.array(top_preds),(len(top_preds)))\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters\n",
            "\n",
            "It took 104.26081832647324 mins\n",
            "Best parameters for SVM with polynomial kernal:\n",
            "{'C': 0.1, 'degree': 3, 'gamma': 1, 'kernel': 'poly'}\n",
            "With mean score of MSE: 327.96722913323015\n",
            "With mean score of MAE: 11.468113719997291\n",
            "With mean score of RMSE: 11.468113719997291\n",
            "Cad concentration mean: 21.378179166666666\n",
            "correlation between y_true and y_preds: 0.8465734704461704\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZcqKzv0XU6O",
        "colab_type": "text"
      },
      "source": [
        "# SVM with linear kernal\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RKnjorEXU6P",
        "colab_type": "code",
        "outputId": "e07d553c-42ad-45a7-8ffe-afcf6a0b9040",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "current=time()\n",
        "\n",
        "#create the model \n",
        "poly_svr= SVR()\n",
        "\n",
        "#gird of parameters for RBF kernal\n",
        "tuned_parameters = [{'kernel': ['linear'],'C': [0.0001,0.001,0.01,0.1,0.5,1,3,5,10,1000]}]\n",
        "\n",
        "best_parameters=None\n",
        "top_mean_rmse_error=10000000\n",
        "top_mean_mse_error=10000000\n",
        "top_mean_mae_error=10000000\n",
        "top_mean_mape_error=10000000\n",
        "top_y_true=[]\n",
        "top_preds=[]\n",
        "\n",
        "print(\"# Tuning hyper-parameters\" )\n",
        "print()\n",
        "# Simulating grid search \n",
        "for g in ParameterGrid(tuned_parameters):\n",
        "    # for each possible combination in the grid\n",
        "    svm= SVR(**g)\n",
        "    mse_scores=[]\n",
        "    mae_scores=[]\n",
        "    rmse_scores=[]\n",
        "    mape_scores=[]\n",
        "    y_true=[]\n",
        "    preds=[]\n",
        "    # doing 1 leave out cross validation\n",
        "    loo = LeaveOneOut()\n",
        "    loo.get_n_splits(X_train)\n",
        "    for train_index, test_index in loo.split(X_train):\n",
        "        X_train_cross, X_test_cross = X_train[train_index,:], X_train[test_index,:]\n",
        "        y_train_cross, y_test_cross = y_train[train_index], y_train[test_index]\n",
        "        \n",
        "        svm.fit(X_train_cross,y_train_cross)\n",
        "        pred=svm.predict(X_test_cross)\n",
        "        \n",
        "        preds.append(pred)\n",
        "        y_true.append(y_test_cross.values[0])\n",
        "        \n",
        "        mse=mean_squared_error(y_test_cross,pred)\n",
        "        mae=mean_absolute_error(y_test_cross,pred)\n",
        "        mape=mean_absolute_percentage_error(y_test_cross,pred)\n",
        "        \n",
        "        mse_scores.append(mse)\n",
        "        mae_scores.append(mae)\n",
        "        rmse_scores.append(np.sqrt(mse))\n",
        "        mape_scores.append(mape)\n",
        "\n",
        "    if np.mean(rmse_scores) < top_mean_rmse_error:\n",
        "        top_mean_mse_error=np.mean(mse_scores) \n",
        "        top_mean_mae_error=np.mean(mae_scores)\n",
        "        top_mean_rmse_error=np.mean(rmse_scores)\n",
        "        top_mean_mape_error=np.mean(mape_scores)\n",
        "        best_parameters=g\n",
        "        top_y_true=y_true\n",
        "        top_preds=preds\n",
        "    \n",
        "      \n",
        "print(\"It took \"+ str((time()-current)/60)+\" mins\")\n",
        "print(\"Best parameters for SVM with linear kernal:\")\n",
        "print(best_parameters)\n",
        "print(\"With mean score of MSE:\",top_mean_mse_error)\n",
        "print(\"With mean score of MAE:\",top_mean_mae_error)\n",
        "print(\"With mean score of RMSE:\",top_mean_mae_error)\n",
        "# print(\"With mean score of MAPE:\",top_mean_mae_error)\n",
        "print(\"Cad concentration mean:\",np.mean(y_train))\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': top_y_true,\n",
        "     'lst2Title': np.reshape(np.array(top_preds),(len(top_preds)))\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters\n",
            "\n",
            "It took 0.015471903483072917 mins\n",
            "Best parameters for SVM with linear kernal:\n",
            "{'C': 1000, 'kernel': 'linear'}\n",
            "With mean score of MSE: 488.3853739489868\n",
            "With mean score of MAE: 12.588535952621989\n",
            "With mean score of RMSE: 12.588535952621989\n",
            "Cad concentration mean: 21.378179166666666\n",
            "correlation between y_true and y_preds: 0.7377745374039979\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5pjwQOMXU6R",
        "colab_type": "text"
      },
      "source": [
        "# SVM with RBF kernal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MO8pJ0iXU6R",
        "colab_type": "code",
        "outputId": "312f2e4f-c971-4f1d-9a07-7816bbf77950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "current=time()\n",
        "\n",
        "# gird of parameters for RBF kernal \n",
        "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3,1e-5,1e-6,1e-7, 1e-4,1e-2,1e-1,1,10,100],\n",
        "                     'C': [0.0001,0.001,0.01,0.1,0.5,1,3,5,10,1000]}]\n",
        "\n",
        "\n",
        "best_parameters=None\n",
        "top_mean_rmse_error=10000000\n",
        "top_mean_mse_error=10000000\n",
        "top_mean_mae_error=10000000\n",
        "top_mean_mape_error=10000000\n",
        "top_y_true=[]\n",
        "top_preds=[]\n",
        "\n",
        "print(\"# Tuning hyper-parameters\" )\n",
        "print()\n",
        "# Simulating grid search \n",
        "for g in ParameterGrid(tuned_parameters):\n",
        "    # for each possible combination in the grid\n",
        "    svm= SVR(**g)\n",
        "    mse_scores=[]\n",
        "    mae_scores=[]\n",
        "    rmse_scores=[]\n",
        "    mape_scores=[]\n",
        "    y_true=[]\n",
        "    preds=[]\n",
        "    # doing 1 leave out cross validation\n",
        "    loo = LeaveOneOut()\n",
        "    loo.get_n_splits(X_train)\n",
        "    for train_index, test_index in loo.split(X_train):\n",
        "        X_train_cross, X_test_cross = X_train[train_index,:], X_train[test_index,:]\n",
        "        y_train_cross, y_test_cross = y_train[train_index], y_train[test_index]\n",
        "        \n",
        "        svm.fit(X_train_cross,y_train_cross)\n",
        "        pred=svm.predict(X_test_cross)\n",
        "        \n",
        "        preds.append(pred)\n",
        "        y_true.append(y_test_cross.values[0])\n",
        "        \n",
        "        mse=mean_squared_error(y_test_cross,pred)\n",
        "        mae=mean_absolute_error(y_test_cross,pred)\n",
        "        mape=mean_absolute_percentage_error(y_test_cross,pred)\n",
        "        \n",
        "        mse_scores.append(mse)\n",
        "        mae_scores.append(mae)\n",
        "        rmse_scores.append(np.sqrt(mse))\n",
        "        mape_scores.append(mape)\n",
        "\n",
        "    if np.mean(rmse_scores) < top_mean_rmse_error:\n",
        "        top_mean_mse_error=np.mean(mse_scores) \n",
        "        top_mean_mae_error=np.mean(mae_scores)\n",
        "        top_mean_rmse_error=np.mean(rmse_scores)\n",
        "        top_mean_mape_error=np.mean(mape_scores)\n",
        "        best_parameters=g\n",
        "        top_y_true=y_true\n",
        "        top_preds=preds\n",
        "    \n",
        "      \n",
        "print(\"It took \"+ str((time()-current)/60)+\" mins\")\n",
        "print(\"Best parameters for SVM with RBF kernal:\")\n",
        "print(best_parameters)\n",
        "print(\"With mean score of MSE:\",top_mean_mse_error)\n",
        "print(\"With mean score of MAE:\",top_mean_mae_error)\n",
        "print(\"With mean score of RMSE:\",top_mean_mae_error)\n",
        "# print(\"With mean score of MAPE:\",top_mean_mape_error)\n",
        "print(\"Cad concentration mean:\",np.mean(y_train))\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': top_y_true,\n",
        "     'lst2Title': np.reshape(np.array(top_preds),(len(top_preds)))\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters\n",
            "\n",
            "It took 0.08639915386835734 mins\n",
            "Best parameters for SVM with RBF kernal:\n",
            "{'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "With mean score of MSE: 298.02834673182457\n",
            "With mean score of MAE: 11.668780013203614\n",
            "With mean score of RMSE: 11.668780013203614\n",
            "Cad concentration mean: 21.378179166666666\n",
            "correlation between y_true and y_preds: 0.8269223752818368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5j263TsXU6T",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pspfJPXSXU6U",
        "colab_type": "code",
        "outputId": "1228e432-66c1-491a-ea5a-24b727cf4c28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "\n",
        "current=time()\n",
        "\n",
        "# gird of parameters for random forest trees \n",
        "tuned_parameters = [{'n_estimators': [10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,\n",
        "                                      210,220,230,240,250,260,270,280,290,300],\n",
        "                     'random_state': [30],\n",
        "                     'criterion': [\"mae\",\"mse\"],\n",
        "                     'bootstrap': [True,False]}]\n",
        "\n",
        "\n",
        "best_parameters=None\n",
        "top_mean_mse_error=10000000\n",
        "top_mean_mae_error=10000000\n",
        "top_mean_rmse_error=10000000\n",
        "top_mean_mape_error=10000000\n",
        "top_y_true=[]\n",
        "top_preds=[]\n",
        "\n",
        "print(\"# Tuning hyper-parameters\" )\n",
        "print()\n",
        "# Simulating grid search \n",
        "for g in ParameterGrid(tuned_parameters):\n",
        "    # for each possible combination in the grid\n",
        "    model= RandomForestRegressor(**g)\n",
        "    mse_scores=[]\n",
        "    rmse_scores=[]\n",
        "    mae_scores=[]\n",
        "    mape_scores=[]\n",
        "    y_true=[]\n",
        "    preds=[]\n",
        "    # doing 1 leave out cross validation\n",
        "    loo = LeaveOneOut()\n",
        "    loo.get_n_splits(X_train)\n",
        "    for train_index, test_index in loo.split(X_train):\n",
        "        X_train_cross, X_test_cross = X_train[train_index,:], X_train[test_index,:]\n",
        "        y_train_cross, y_test_cross = y_train[train_index], y_train[test_index]\n",
        "        \n",
        "        model.fit(X_train_cross,y_train_cross)\n",
        "        pred=model.predict(X_test_cross)\n",
        "        \n",
        "        preds.append(pred)\n",
        "        y_true.append(y_test_cross.values[0])\n",
        "        \n",
        "        mse=mean_squared_error(y_test_cross,pred)\n",
        "        mae=mean_absolute_error(y_test_cross,pred)\n",
        "        mape=mean_absolute_percentage_error(y_test_cross,pred)\n",
        "        \n",
        "        mse_scores.append(mse)\n",
        "        mae_scores.append(mae)\n",
        "        rmse_scores.append(np.sqrt(mse))\n",
        "        mape_scores.append(mape)\n",
        "\n",
        "    if np.mean(rmse_scores) < top_mean_rmse_error:\n",
        "        top_mean_mse_error=np.mean(mse_scores) \n",
        "        top_mean_mae_error=np.mean(mae_scores) \n",
        "        top_mean_rmse_error=np.mean(rmse_scores)\n",
        "        top_mean_mape_error=np.mean(mape_scores)\n",
        "        best_parameters=g\n",
        "        top_y_true=y_true\n",
        "        top_preds=preds\n",
        "    \n",
        "      \n",
        "print(\"It took \"+ str((time()-current)/60)+\" mins\")\n",
        "print(\"Best parameters for random forest:\")\n",
        "print(best_parameters)\n",
        "print(\"With mean score of MSE:\",top_mean_mse_error)\n",
        "print(\"With mean score of MAE:\",top_mean_mae_error)\n",
        "print(\"With mean score of RMSE:\",top_mean_rmse_error)\n",
        "# print(\"With mean score of MAPE:\",top_mean_mape_error)\n",
        "print(\"Cad concentration mean:\",np.mean(y_train))\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': top_y_true,\n",
        "     'lst2Title': np.reshape(np.array(top_preds),(len(top_preds)))\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters\n",
            "\n",
            "It took 5.1234893798828125 mins\n",
            "Best parameters for M5 regression trees:\n",
            "{'bootstrap': True, 'criterion': 'mse', 'n_estimators': 200, 'random_state': 30}\n",
            "With mean score of MSE: 353.421940114258\n",
            "With mean score of MAE: 9.547843500000003\n",
            "With mean score of RMSE: 9.547843500000003\n",
            "Cad concentration mean: 21.378179166666666\n",
            "correlation between y_true and y_preds: 0.8048902193180997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy8vtFqWsRtj",
        "colab_type": "text"
      },
      "source": [
        "# M5 regression trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll8FFlqPsek8",
        "colab_type": "code",
        "outputId": "f0eecec3-e7e3-477e-b3ea-5f2ca42f605c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "#Source : https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
        "\n",
        "\n",
        "current=time()\n",
        "\n",
        "# gird of parameters for M5 regression trees \n",
        "tuned_parameters = [{'max_features': [\"auto\",\"sqrt\",\"log2\",None],\n",
        "                     'random_state': [30],\n",
        "                     'presort': [True,False],\n",
        "                     'criterion': [\"mae\",\"mse\"]}]\n",
        "\n",
        "\n",
        "best_parameters=None\n",
        "top_mean_mse_error=10000000\n",
        "top_mean_mae_error=10000000\n",
        "top_mean_rmse_error=10000000\n",
        "top_mean_mape_error=10000000\n",
        "top_y_true=[]\n",
        "top_preds=[]\n",
        "\n",
        "print(\"# Tuning hyper-parameters\" )\n",
        "print()\n",
        "# Simulating grid search \n",
        "for g in ParameterGrid(tuned_parameters):\n",
        "    # for each possible combination in the grid\n",
        "    model= DecisionTreeRegressor(**g)\n",
        "    mse_scores=[]\n",
        "    rmse_scores=[]\n",
        "    mae_scores=[]\n",
        "    mape_scores=[]\n",
        "    y_true=[]\n",
        "    preds=[]\n",
        "    # doing 1 leave out cross validation\n",
        "    loo = LeaveOneOut()\n",
        "    loo.get_n_splits(X_train)\n",
        "    for train_index, test_index in loo.split(X_train):\n",
        "        X_train_cross, X_test_cross = X_train[train_index,:], X_train[test_index,:]\n",
        "        y_train_cross, y_test_cross = y_train[train_index], y_train[test_index]\n",
        "        \n",
        "        model.fit(X_train_cross,y_train_cross)\n",
        "        pred=model.predict(X_test_cross)\n",
        "        \n",
        "        preds.append(pred)\n",
        "        y_true.append(y_test_cross.values[0])\n",
        "        \n",
        "        mse=mean_squared_error(y_test_cross,pred)\n",
        "        mae=mean_absolute_error(y_test_cross,pred)\n",
        "        mape=mean_absolute_percentage_error(y_test_cross,pred)\n",
        "        \n",
        "        mse_scores.append(mse)\n",
        "        mae_scores.append(mae)\n",
        "        rmse_scores.append(np.sqrt(mse))\n",
        "        mape_scores.append(mape)\n",
        "\n",
        "    if np.mean(rmse_scores) < top_mean_rmse_error:\n",
        "        top_mean_mse_error=np.mean(mse_scores) \n",
        "        top_mean_mae_error=np.mean(mae_scores) \n",
        "        top_mean_rmse_error=np.mean(rmse_scores)\n",
        "        top_mean_mape_error=np.mean(mape_scores)\n",
        "        best_parameters=g\n",
        "        top_y_true=y_true\n",
        "        top_preds=preds\n",
        "    \n",
        "      \n",
        "print(\"It took \"+ str((time()-current)/60)+\" mins\")\n",
        "print(\"Best parameters for M5 regression trees:\")\n",
        "print(best_parameters)\n",
        "print(\"With mean score of MSE:\",top_mean_mse_error)\n",
        "print(\"With mean score of MAE:\",top_mean_mae_error)\n",
        "print(\"With mean score of RMSE:\",top_mean_rmse_error)\n",
        "# print(\"With mean score of MAPE:\",top_mean_mape_error)\n",
        "print(\"Cad concentration mean:\",np.mean(y_train))\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': top_y_true,\n",
        "     'lst2Title': np.reshape(np.array(top_preds),(len(top_preds)))\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters\n",
            "\n",
            "It took 0.015040377775828043 mins\n",
            "Best parameters for M5 regression trees:\n",
            "{'criterion': 'mae', 'max_features': 'auto', 'presort': True, 'random_state': 30}\n",
            "With mean score of MSE: 352.0632925104167\n",
            "With mean score of MAE: 10.450620833333334\n",
            "With mean score of RMSE: 10.450620833333334\n",
            "Cad concentration mean: 21.378179166666666\n",
            "correlation between y_true and y_preds: 0.7842051405185578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSMm1R-Ksf7i",
        "colab_type": "text"
      },
      "source": [
        "# GradientBoostingRegressor (GBDT )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGquofEQsqQf",
        "colab_type": "code",
        "outputId": "a2afba82-cee5-491f-cccf-b7ba49b5c964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "#Source : https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
        "\n",
        "current=time()\n",
        "\n",
        "# gird of parameters for GBDT\n",
        "tuned_parameters = [{'loss': ['ls', 'lad' ,'huber'],   \n",
        "                     'learning_rate' : [0.001,0.01,0.1],\n",
        "                     'n_estimators' : [10,40,60,100,160],\n",
        "                     'random_state': [30],\n",
        "                     'criterion': [\"friedman_mse\"],\n",
        "                     'max_features': [\"auto\",\"sqrt\",\"log2\"],\n",
        "                     'max_depth': [3,6,9,12,16]\n",
        "                    }]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "best_parameters=None\n",
        "top_mean_mse_error=10000000\n",
        "top_mean_mae_error=10000000\n",
        "top_mean_rmse_error=10000000\n",
        "top_mean_mape_error=10000000\n",
        "top_y_true=[]\n",
        "top_preds=[]\n",
        "\n",
        "print(\"# Tuning hyper-parameters\" )\n",
        "print()\n",
        "# Simulating grid search \n",
        "for g in ParameterGrid(tuned_parameters):\n",
        "    # for each possible combination in the grid\n",
        "    model= GradientBoostingRegressor(**g)\n",
        "    mse_scores=[]\n",
        "    rmse_scores=[]\n",
        "    mae_scores=[]\n",
        "    mape_scores=[]\n",
        "    y_true=[]\n",
        "    preds=[]\n",
        "    # doing 1 leave out cross validation\n",
        "    loo = LeaveOneOut()\n",
        "    loo.get_n_splits(X_train)\n",
        "    for train_index, test_index in loo.split(X_train):\n",
        "        X_train_cross, X_test_cross = X_train[train_index,:], X_train[test_index,:]\n",
        "        y_train_cross, y_test_cross = y_train[train_index], y_train[test_index]\n",
        "        \n",
        "        model.fit(X_train_cross,y_train_cross)\n",
        "        pred=model.predict(X_test_cross)\n",
        "        \n",
        "        preds.append(pred)\n",
        "        y_true.append(y_test_cross.values[0])\n",
        "        \n",
        "        mse=mean_squared_error(y_test_cross,pred)\n",
        "        mae=mean_absolute_error(y_test_cross,pred)\n",
        "        mape=mean_absolute_percentage_error(y_test_cross,pred)\n",
        "        \n",
        "        mse_scores.append(mse)\n",
        "        mae_scores.append(mae)\n",
        "        rmse_scores.append(np.sqrt(mse))\n",
        "        mape_scores.append(mape)\n",
        "\n",
        "    if np.mean(rmse_scores) < top_mean_rmse_error:\n",
        "        top_mean_mse_error=np.mean(mse_scores) \n",
        "        top_mean_mae_error=np.mean(mae_scores) \n",
        "        top_mean_rmse_error=np.mean(rmse_scores)\n",
        "        top_mean_mape_error=np.mean(mape_scores)\n",
        "        best_parameters=g\n",
        "        top_y_true=y_true\n",
        "        top_preds=preds\n",
        "    \n",
        "      \n",
        "print(\"It took \"+ str((time()-current)/60)+\" mins\")\n",
        "print(\"Best parameters for GBDT:\")\n",
        "print(best_parameters)\n",
        "print(\"With mean score of MSE:\",top_mean_mse_error)\n",
        "print(\"With mean score of MAE:\",top_mean_mae_error)\n",
        "print(\"With mean score of RMSE:\",top_mean_rmse_error)\n",
        "# print(\"With mean score of MAPE:\",top_mean_mape_error)\n",
        "print(\"Cad concentration mean:\",np.mean(y_train))\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': top_y_true,\n",
        "     'lst2Title': np.reshape(np.array(top_preds),(len(top_preds)))\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters\n",
            "\n",
            "It took 18.799745798110962 mins\n",
            "Best parameters for GBDT:\n",
            "{'criterion': 'friedman_mse', 'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 3, 'max_features': 'auto', 'n_estimators': 160, 'random_state': 30}\n",
            "With mean score of MSE: 290.84976958856276\n",
            "With mean score of MAE: 9.133561697742168\n",
            "With mean score of RMSE: 9.133561697742168\n",
            "Cad concentration mean: 21.378179166666666\n",
            "correlation between y_true and y_preds: 0.8291035561011352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1iAbzeZt1Vl",
        "colab_type": "text"
      },
      "source": [
        "# CatBoostRegressor "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs9v9n57t6vy",
        "colab_type": "code",
        "outputId": "d5f0e4f6-6500-44ff-d480-92085bcfdbae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "#Source : https://catboost.ai/docs/concepts/python-reference_catboostregressor.html\n",
        "\n",
        "\n",
        "current=time()\n",
        "\n",
        "# gird of parameters for CatBoostRegressor\n",
        "tuned_parameters = [{'depth':[3,6,12], \n",
        "          #'iterations':[250,100,500],\n",
        "          'learning_rate':[0.001,0.01,0.1,0.3], \n",
        "          'l2_leaf_reg':[3,1,5,10,100],\n",
        "#           'border_count':[32,5,10,20,50,100,200],\n",
        "          #'thread_count':[4],\n",
        "           'verbose':[0]}]\n",
        "\n",
        "\n",
        "best_parameters=None\n",
        "top_mean_mse_error=10000000\n",
        "top_mean_mae_error=10000000\n",
        "top_mean_rmse_error=10000000\n",
        "top_mean_mape_error=10000000\n",
        "top_y_true=[]\n",
        "top_preds=[]\n",
        "\n",
        "counter =0\n",
        "print(\"# Tuning hyper-parameters\" )\n",
        "print()\n",
        "# Simulating grid search \n",
        "for g in ParameterGrid(tuned_parameters):\n",
        "    counter=counter+1\n",
        "    if counter %10 ==0:\n",
        "      print(counter)\n",
        "    # for each possible combination in the grid\n",
        "    model= CatBoostRegressor(**g)\n",
        "    mse_scores=[]\n",
        "    rmse_scores=[]\n",
        "    mae_scores=[]\n",
        "    mape_scores=[]\n",
        "    y_true=[]\n",
        "    preds=[]\n",
        "    # doing 1 leave out cross validation\n",
        "    loo = LeaveOneOut()\n",
        "    loo.get_n_splits(X_train)\n",
        "    for train_index, test_index in loo.split(X_train):\n",
        "        X_train_cross, X_test_cross = X_train[train_index,:], X_train[test_index,:]\n",
        "        y_train_cross, y_test_cross = y_train[train_index], y_train[test_index]\n",
        "        \n",
        "        model.fit(X_train_cross,y_train_cross)\n",
        "        pred=model.predict(X_test_cross)\n",
        "        \n",
        "        preds.append(pred)\n",
        "        y_true.append(y_test_cross.values[0])\n",
        "        \n",
        "        mse=mean_squared_error(y_test_cross,pred)\n",
        "        mae=mean_absolute_error(y_test_cross,pred)\n",
        "        mape=mean_absolute_percentage_error(y_test_cross,pred)\n",
        "        \n",
        "        mse_scores.append(mse)\n",
        "        mae_scores.append(mae)\n",
        "        rmse_scores.append(np.sqrt(mse))\n",
        "        mape_scores.append(mape)\n",
        "\n",
        "    if np.mean(rmse_scores) < top_mean_rmse_error:\n",
        "        top_mean_mse_error=np.mean(mse_scores) \n",
        "        top_mean_mae_error=np.mean(mae_scores) \n",
        "        top_mean_rmse_error=np.mean(rmse_scores)\n",
        "        top_mean_mape_error=np.mean(mape_scores)\n",
        "        best_parameters=g\n",
        "        top_y_true=y_true\n",
        "        top_preds=preds\n",
        "\n",
        "print(\"It took \"+ str((time()-current)/60)+\" mins\")\n",
        "print(\"Best parameters for CatBoostRegressor:\")\n",
        "print(best_parameters)\n",
        "print(\"With mean score of MSE:\",top_mean_mse_error)\n",
        "print(\"With mean score of MAE:\",top_mean_mae_error)\n",
        "print(\"With mean score of RMSE:\",top_mean_rmse_error)\n",
        "# print(\"With mean score of MAPE:\",top_mean_mape_error)\n",
        "print(\"Cad concentration mean:\",np.mean(y_train))\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': top_y_true,\n",
        "     'lst2Title': np.reshape(np.array(top_preds),(len(top_preds)))\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters\n",
            "\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "It took 30.592853625615437 mins\n",
            "Best parameters for CatBoostRegressor:\n",
            "{'depth': 3, 'l2_leaf_reg': 10, 'learning_rate': 0.01, 'verbose': 0}\n",
            "With mean score of MSE: 654.9698620666114\n",
            "With mean score of MAE: 11.403836548977162\n",
            "With mean score of RMSE: 11.403836548977162\n",
            "Cad concentration mean: 21.378179166666666\n",
            "correlation between y_true and y_preds: 0.5747472009449256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anrOjO0qrGdK",
        "colab_type": "text"
      },
      "source": [
        "# Picking the final Model for top feaures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPKHNFLMXU6W",
        "colab_type": "code",
        "outputId": "54734a9b-0d57-441f-de6b-1e3374c4787a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(\"Cad concentration mean:\",np.mean(y))\n",
        "print(\"---------------------------------------------------\\n\")  \n",
        "\n",
        "# retrain all the models on the best tuned hyper-parameters\n",
        "svm_poly=SVR(**{'C': 0.1, 'degree': 3, 'gamma': 1, 'kernel': 'poly'})\n",
        "svm_poly.fit(X_train,y_train)\n",
        "preds=svm_poly.predict(X_test)\n",
        "#scores:\n",
        "mse=mean_squared_error(y_test,preds)\n",
        "mae=mean_absolute_error(y_test,preds)\n",
        "mape=mean_absolute_percentage_error(y_test,preds)\n",
        "r2=r2_score(y_test,preds)\n",
        "rmse=np.sqrt(mse)\n",
        "print(\"SVM with polinomial kernel, results on the testing data set:\")\n",
        "print(\"MSE:\",mse)\n",
        "print(\"RMSE: \",rmse)\n",
        "print(\"MAE:\",mae)\n",
        "print(\"MAPE: \",mape)\n",
        "print(\"R2: \",r2)\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': y_test,\n",
        "     'lst2Title': preds\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))\n",
        "print(\"---------------------------------------------------\\n\")  \n",
        "\n",
        "svm_rbf=SVR(**{'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'})\n",
        "svm_rbf.fit(X_train,y_train)\n",
        "preds=svm_rbf.predict(X_test)\n",
        "#scores:\n",
        "mse=mean_squared_error(y_test,preds)\n",
        "mae=mean_absolute_error(y_test,preds)\n",
        "mape=mean_absolute_percentage_error(y_test,preds)\n",
        "r2=r2_score(y_test,preds)\n",
        "rmse=np.sqrt(mse)\n",
        "print(\"SVM with RBF kernel, results on the testing data set:\")\n",
        "print(\"MSE:\",mse)\n",
        "print(\"RMSE: \",rmse)\n",
        "print(\"MAE:\",mae)\n",
        "print(\"MAPE: \",mape)\n",
        "print(\"R2: \",r2)\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': y_test,\n",
        "     'lst2Title': preds\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))\n",
        "print(\"---------------------------------------------------\\n\") \n",
        "\n",
        "svm_linear=SVR(**{'C': 1000, 'kernel': 'linear'})\n",
        "svm_linear.fit(X_train,y_train)\n",
        "preds=svm_linear.predict(X_test)\n",
        "#scores:\n",
        "mse=mean_squared_error(y_test,preds)\n",
        "mae=mean_absolute_error(y_test,preds)\n",
        "mape=mean_absolute_percentage_error(y_test,preds)\n",
        "r2=r2_score(y_test,preds)\n",
        "rmse=np.sqrt(mse)\n",
        "print(\"SVM with linear kernel, results on the testing data set:\")\n",
        "print(\"MSE:\",mse)\n",
        "print(\"RMSE: \",rmse)\n",
        "print(\"MAE:\",mae)\n",
        "print(\"MAPE: \",mape)\n",
        "print(\"R2: \",r2)\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': y_test,\n",
        "     'lst2Title': preds\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))\n",
        "print(\"---------------------------------------------------\\n\")\n",
        "\n",
        "randomForest=RandomForestRegressor(**{'bootstrap': True, 'criterion': 'mse', 'n_estimators': 200, 'random_state': 30})\n",
        "randomForest.fit(X_train,y_train)\n",
        "preds=randomForest.predict(X_test)\n",
        "#scores:\n",
        "mse=mean_squared_error(y_test,preds)\n",
        "mae=mean_absolute_error(y_test,preds)\n",
        "mape=mean_absolute_percentage_error(y_test,preds)\n",
        "r2=r2_score(y_test,preds)\n",
        "rmse=np.sqrt(mse)\n",
        "print(\"Random forest results on the testing data set:\")\n",
        "print(\"MSE:\",mse)\n",
        "print(\"RMSE: \",rmse)\n",
        "print(\"MAE:\",mae)\n",
        "print(\"MAPE: \",mape)\n",
        "print(\"R2: \",r2)\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': y_test,\n",
        "     'lst2Title': preds\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))\n",
        "print(\"---------------------------------------------------\\n\")\n",
        "\n",
        "\n",
        "m5_regression=DecisionTreeRegressor(**{'criterion': 'mae', 'max_features': 'auto', 'presort': True, 'random_state': 30})\n",
        "m5_regression.fit(X_train,y_train)\n",
        "preds=m5_regression.predict(X_test)\n",
        "#scores:\n",
        "mse=mean_squared_error(y_test,preds)\n",
        "mae=mean_absolute_error(y_test,preds)\n",
        "mape=mean_absolute_percentage_error(y_test,preds)\n",
        "r2=r2_score(y_test,preds)\n",
        "rmse=np.sqrt(mse)\n",
        "print(\"M5 regression trees results on the testing data set:\")\n",
        "print(\"MSE:\",mse)\n",
        "print(\"RMSE: \",rmse)\n",
        "print(\"MAE:\",mae)\n",
        "print(\"MAPE: \",mape)\n",
        "print(\"R2: \",r2)\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': y_test,\n",
        "     'lst2Title': preds\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))\n",
        "print(\"---------------------------------------------------\\n\")\n",
        "\n",
        "# to add optimal paraeters: \n",
        "\n",
        "GBDT=GradientBoostingRegressor(**{'criterion': 'friedman_mse', 'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 3, 'max_features': 'auto', 'n_estimators': 160, 'random_state': 30})\n",
        "GBDT.fit(X_train,y_train)\n",
        "preds=GBDT.predict(X_test)\n",
        "#scores:\n",
        "mse=mean_squared_error(y_test,preds)\n",
        "mae=mean_absolute_error(y_test,preds)\n",
        "mape=mean_absolute_percentage_error(y_test,preds)\n",
        "r2=r2_score(y_test,preds)\n",
        "rmse=np.sqrt(mse)\n",
        "print(\"GBDT results on the testing data set:\")\n",
        "print(\"MSE:\",mse)\n",
        "print(\"RMSE: \",rmse)\n",
        "print(\"MAE:\",mae)\n",
        "print(\"MAPE: \",mape)\n",
        "print(\"R2: \",r2)\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': y_test,\n",
        "     'lst2Title': preds\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))\n",
        "print(\"---------------------------------------------------\\n\")\n",
        "\n",
        "catBostReg=CatBoostRegressor(**{'depth': 3, 'l2_leaf_reg': 10, 'learning_rate': 0.01, 'verbose': 0})\n",
        "catBostReg.fit(X_train,y_train)\n",
        "preds=catBostReg.predict(X_test)\n",
        "#scores:\n",
        "mse=mean_squared_error(y_test,preds)\n",
        "mae=mean_absolute_error(y_test,preds)\n",
        "mape=mean_absolute_percentage_error(y_test,preds)\n",
        "r2=r2_score(y_test,preds)\n",
        "rmse=np.sqrt(mse)\n",
        "print(\"CatBoostRegressor results on the testing data set:\")\n",
        "print(\"MSE:\",mse)\n",
        "print(\"RMSE: \",rmse)\n",
        "print(\"MAE:\",mae)\n",
        "print(\"MAPE: \",mape)\n",
        "print(\"R2: \",r2)\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': y_test,\n",
        "     'lst2Title': preds\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))\n",
        "print(\"---------------------------------------------------\\n\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cad concentration mean: 24.001398387096778\n",
            "---------------------------------------------------\n",
            "\n",
            "SVM with polinomial kernel, results on the testing data set:\n",
            "MSE: 1601.896559309708\n",
            "RMSE:  40.02369997026397\n",
            "MAE: 30.542780930836972\n",
            "MAPE:  150.7009683122459\n",
            "R2:  -0.40230539014173283\n",
            "correlation between y_true and y_preds: 0.4039695868031746\n",
            "---------------------------------------------------\n",
            "\n",
            "SVM with RBF kernel, results on the testing data set:\n",
            "MSE: 574.9250235700468\n",
            "RMSE:  23.977594198960972\n",
            "MAE: 17.414043228753613\n",
            "MAPE:  60.894486367151416\n",
            "R2:  0.4967087888452314\n",
            "correlation between y_true and y_preds: 0.7157050595787596\n",
            "---------------------------------------------------\n",
            "\n",
            "SVM with linear kernel, results on the testing data set:\n",
            "MSE: 787.646002646928\n",
            "RMSE:  28.065031670157225\n",
            "MAE: 18.888877365171634\n",
            "MAPE:  59.44890752305951\n",
            "R2:  0.310492160922464\n",
            "correlation between y_true and y_preds: 0.6854404724309975\n",
            "---------------------------------------------------\n",
            "\n",
            "Random forest results on the testing data set:\n",
            "MSE: 553.2888628488587\n",
            "RMSE:  23.52209307967424\n",
            "MAE: 16.185347428571436\n",
            "MAPE:  76.66434732834362\n",
            "R2:  0.5156491533930956\n",
            "correlation between y_true and y_preds: 0.7241600330625739\n",
            "---------------------------------------------------\n",
            "\n",
            "M5 regression trees results on the testing data set:\n",
            "MSE: 2093.7345676275\n",
            "RMSE:  45.75734441188103\n",
            "MAE: 28.962764285714286\n",
            "MAPE:  152.92509776514788\n",
            "R2:  -0.8328619614335919\n",
            "correlation between y_true and y_preds: 0.4205362424987099\n",
            "---------------------------------------------------\n",
            "\n",
            "GBDT results on the testing data set:\n",
            "MSE: 817.288442072344\n",
            "RMSE:  28.58825706601128\n",
            "MAE: 17.322413298289785\n",
            "MAPE:  75.07009810376847\n",
            "R2:  0.2845430742965941\n",
            "correlation between y_true and y_preds: 0.6552377862363714\n",
            "---------------------------------------------------\n",
            "\n",
            "CatBoostRegressor results on the testing data set:\n",
            "MSE: 598.2649202707538\n",
            "RMSE:  24.459454619241896\n",
            "MAE: 15.397525693204829\n",
            "MAPE:  36.719553116979064\n",
            "R2:  0.47627696835186784\n",
            "correlation between y_true and y_preds: 0.7814346276031137\n",
            "---------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiPkljSLqlUl",
        "colab_type": "text"
      },
      "source": [
        "# Tuning Hyper-Parameters on all features + modeling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U2KK0T6uQCq",
        "colab_type": "code",
        "outputId": "c09888c8-2452-4633-cb29-7e6704782c50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(X_train.shape,X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24, 66) (7, 66)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dSVGbTcq41q",
        "colab_type": "text"
      },
      "source": [
        "# SVM with polinomial kernal (all Features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzRnS0SFyYub",
        "colab_type": "code",
        "outputId": "a62f7f3d-ec98-48cb-fb9f-1bc9bcfb4f19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "current=time()\n",
        "\n",
        " # gird of parameters for poly kernal\n",
        "tuned_parameters = [{'kernel': ['poly'], 'gamma': [1e-3,1e-6,1e-2,1e-1,1,10,100],'degree':[2,3,4,5,6,7],\n",
        "                     'C': [0.0001,0.01,0.1,0.5,1,3,5,10,1000]}]\n",
        "\n",
        "\n",
        "best_parameters=None\n",
        "top_mean_rmse_error=10000000\n",
        "top_mean_mse_error=10000000\n",
        "top_mean_mae_error=10000000\n",
        "top_mean_mape_error=10000000\n",
        "top_y_true=[]\n",
        "top_preds=[]\n",
        "\n",
        "print(\"# Tuning hyper-parameters\" )\n",
        "print()\n",
        "# Simulating grid search \n",
        "for g in ParameterGrid(tuned_parameters):\n",
        "    # for each possible combination in the grid\n",
        "    svm= SVR(**g)\n",
        "    mse_scores=[]\n",
        "    mae_scores=[]\n",
        "    rmse_scores=[]\n",
        "    mape_scores=[]\n",
        "    y_true=[]\n",
        "    preds=[]\n",
        "    # doing 1 leave out cross validation\n",
        "    loo = LeaveOneOut()\n",
        "    loo.get_n_splits(X_train)\n",
        "    for train_index, test_index in loo.split(X_train):\n",
        "        X_train_cross, X_test_cross = X_train[train_index,:], X_train[test_index,:]\n",
        "        y_train_cross, y_test_cross = y_train[train_index], y_train[test_index]\n",
        "        \n",
        "        svm.fit(X_train_cross,y_train_cross)\n",
        "        pred=svm.predict(X_test_cross)\n",
        "        \n",
        "        preds.append(pred)\n",
        "        y_true.append(y_test_cross.values[0])\n",
        "        \n",
        "        mse=mean_squared_error(y_test_cross,pred)\n",
        "        mae=mean_absolute_error(y_test_cross,pred)\n",
        "        mape=mean_absolute_percentage_error(y_test_cross,pred)\n",
        "        \n",
        "        mse_scores.append(mse)\n",
        "        mae_scores.append(mae)\n",
        "        rmse_scores.append(np.sqrt(mse))\n",
        "        mape_scores.append(mape)\n",
        "        \n",
        "    if np.mean(rmse_scores) < top_mean_rmse_error:\n",
        "        top_mean_mse_error=np.mean(mse_scores) \n",
        "        top_mean_mae_error=np.mean(mae_scores)\n",
        "        top_mean_rmse_error=np.mean(rmse_scores)\n",
        "        top_mean_mape_error=np.mean(mape_scores)\n",
        "        best_parameters=g\n",
        "        top_y_true=y_true\n",
        "        top_preds=preds\n",
        "    \n",
        "      \n",
        "print(\"It took \"+ str((time()-current)/60)+\" mins\")\n",
        "print(\"Best parameters for SVM with polynomial kernal:\")\n",
        "print(best_parameters)\n",
        "print(\"With mean score of MSE:\",top_mean_mse_error)\n",
        "print(\"With mean score of MAE:\",top_mean_mae_error)\n",
        "print(\"With mean score of RMSE:\",top_mean_rmse_error)\n",
        "# print(\"With mean score of MAPE:\",top_mean_mape_error)\n",
        "print(\"Cad concentration mean:\",np.mean(y_train))\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': top_y_true,\n",
        "     'lst2Title': np.reshape(np.array(top_preds),(len(top_preds)))\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters\n",
            "\n",
            "It took 0.3864992380142212 mins\n",
            "Best parameters for SVM with polynomial kernal:\n",
            "{'C': 0.1, 'degree': 3, 'gamma': 0.1, 'kernel': 'poly'}\n",
            "With mean score of MSE: 867.9132021101668\n",
            "With mean score of MAE: 16.750771480909307\n",
            "With mean score of RMSE: 16.750771480909307\n",
            "Cad concentration mean: 21.378179166666666\n",
            "correlation between y_true and y_preds: 0.39150083859353524\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZGJTxj2q6rs",
        "colab_type": "text"
      },
      "source": [
        "# SVM with Linear kernal (all Features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEYN9KgiuUcv",
        "colab_type": "code",
        "outputId": "2d017fb5-d994-4e94-c812-250ab4ab6b1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "current=time()\n",
        "\n",
        "#create the model \n",
        "poly_svr= SVR()\n",
        "\n",
        "#gird of parameters for RBF kernal\n",
        "tuned_parameters = [{'kernel': ['linear'],'C': [0.0001,0.001,0.01,0.1,0.5,1,3,5,10,1000]}]\n",
        "\n",
        "best_parameters=None\n",
        "top_mean_rmse_error=10000000\n",
        "top_mean_mse_error=10000000\n",
        "top_mean_mae_error=10000000\n",
        "top_mean_mape_error=10000000\n",
        "top_y_true=[]\n",
        "top_preds=[]\n",
        "\n",
        "print(\"# Tuning hyper-parameters\" )\n",
        "print()\n",
        "# Simulating grid search \n",
        "for g in ParameterGrid(tuned_parameters):\n",
        "    # for each possible combination in the grid\n",
        "    svm= SVR(**g)\n",
        "    mse_scores=[]\n",
        "    mae_scores=[]\n",
        "    rmse_scores=[]\n",
        "    mape_scores=[]\n",
        "    y_true=[]\n",
        "    preds=[]\n",
        "    # doing 1 leave out cross validation\n",
        "    loo = LeaveOneOut()\n",
        "    loo.get_n_splits(X_train)\n",
        "    for train_index, test_index in loo.split(X_train):\n",
        "        X_train_cross, X_test_cross = X_train[train_index,:], X_train[test_index,:]\n",
        "        y_train_cross, y_test_cross = y_train[train_index], y_train[test_index]\n",
        "        \n",
        "        svm.fit(X_train_cross,y_train_cross)\n",
        "        pred=svm.predict(X_test_cross)\n",
        "        \n",
        "        preds.append(pred)\n",
        "        y_true.append(y_test_cross.values[0])\n",
        "        \n",
        "        mse=mean_squared_error(y_test_cross,pred)\n",
        "        mae=mean_absolute_error(y_test_cross,pred)\n",
        "        mape=mean_absolute_percentage_error(y_test_cross,pred)\n",
        "        \n",
        "        mse_scores.append(mse)\n",
        "        mae_scores.append(mae)\n",
        "        rmse_scores.append(np.sqrt(mse))\n",
        "        mape_scores.append(mape)\n",
        "\n",
        "    if np.mean(rmse_scores) < top_mean_rmse_error:\n",
        "        top_mean_mse_error=np.mean(mse_scores) \n",
        "        top_mean_mae_error=np.mean(mae_scores)\n",
        "        top_mean_rmse_error=np.mean(rmse_scores)\n",
        "        top_mean_mape_error=np.mean(mape_scores)\n",
        "        best_parameters=g\n",
        "        top_y_true=y_true\n",
        "        top_preds=preds\n",
        "    \n",
        "      \n",
        "print(\"It took \"+ str((time()-current)/60)+\" mins\")\n",
        "print(\"Best parameters for SVM with linear kernal:\")\n",
        "print(best_parameters)\n",
        "print(\"With mean score of MSE:\",top_mean_mse_error)\n",
        "print(\"With mean score of MAE:\",top_mean_mae_error)\n",
        "print(\"With mean score of RMSE:\",top_mean_mae_error)\n",
        "# print(\"With mean score of MAPE:\",top_mean_mae_error)\n",
        "print(\"Cad concentration mean:\",np.mean(y_train))\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': top_y_true,\n",
        "     'lst2Title': np.reshape(np.array(top_preds),(len(top_preds)))\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters\n",
            "\n",
            "It took 0.011318596204121907 mins\n",
            "Best parameters for SVM with linear kernal:\n",
            "{'C': 0.1, 'kernel': 'linear'}\n",
            "With mean score of MSE: 962.5069507168761\n",
            "With mean score of MAE: 16.70524799774698\n",
            "With mean score of RMSE: 16.70524799774698\n",
            "Cad concentration mean: 21.378179166666666\n",
            "correlation between y_true and y_preds: 0.16922168964960382\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq9r0sYsq8eU",
        "colab_type": "text"
      },
      "source": [
        "# SVM with RBF kernal (all Features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0UqZHv0urLS",
        "colab_type": "code",
        "outputId": "9182d0ed-ef41-4252-ac61-290603d82acb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "current=time()\n",
        "\n",
        "# gird of parameters for RBF kernal \n",
        "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3,1e-5,1e-6,1e-7, 1e-4,1e-2,1e-1,1,10,100],\n",
        "                     'C': [0.0001,0.001,0.01,0.1,0.5,1,3,5,10,1000]}]\n",
        "\n",
        "\n",
        "best_parameters=None\n",
        "top_mean_rmse_error=10000000\n",
        "top_mean_mse_error=10000000\n",
        "top_mean_mae_error=10000000\n",
        "top_mean_mape_error=10000000\n",
        "top_y_true=[]\n",
        "top_preds=[]\n",
        "\n",
        "print(\"# Tuning hyper-parameters\" )\n",
        "print()\n",
        "# Simulating grid search \n",
        "for g in ParameterGrid(tuned_parameters):\n",
        "    # for each possible combination in the grid\n",
        "    svm= SVR(**g)\n",
        "    mse_scores=[]\n",
        "    mae_scores=[]\n",
        "    rmse_scores=[]\n",
        "    mape_scores=[]\n",
        "    y_true=[]\n",
        "    preds=[]\n",
        "    # doing 1 leave out cross validation\n",
        "    loo = LeaveOneOut()\n",
        "    loo.get_n_splits(X_train)\n",
        "    for train_index, test_index in loo.split(X_train):\n",
        "        X_train_cross, X_test_cross = X_train[train_index,:], X_train[test_index,:]\n",
        "        y_train_cross, y_test_cross = y_train[train_index], y_train[test_index]\n",
        "        \n",
        "        svm.fit(X_train_cross,y_train_cross)\n",
        "        pred=svm.predict(X_test_cross)\n",
        "        \n",
        "        preds.append(pred)\n",
        "        y_true.append(y_test_cross.values[0])\n",
        "        \n",
        "        mse=mean_squared_error(y_test_cross,pred)\n",
        "        mae=mean_absolute_error(y_test_cross,pred)\n",
        "        mape=mean_absolute_percentage_error(y_test_cross,pred)\n",
        "        \n",
        "        mse_scores.append(mse)\n",
        "        mae_scores.append(mae)\n",
        "        rmse_scores.append(np.sqrt(mse))\n",
        "        mape_scores.append(mape)\n",
        "\n",
        "    if np.mean(rmse_scores) < top_mean_rmse_error:\n",
        "        top_mean_mse_error=np.mean(mse_scores) \n",
        "        top_mean_mae_error=np.mean(mae_scores)\n",
        "        top_mean_rmse_error=np.mean(rmse_scores)\n",
        "        top_mean_mape_error=np.mean(mape_scores)\n",
        "        best_parameters=g\n",
        "        top_y_true=y_true\n",
        "        top_preds=preds\n",
        "    \n",
        "      \n",
        "print(\"It took \"+ str((time()-current)/60)+\" mins\")\n",
        "print(\"Best parameters for SVM with RBF kernal:\")\n",
        "print(best_parameters)\n",
        "print(\"With mean score of MSE:\",top_mean_mse_error)\n",
        "print(\"With mean score of MAE:\",top_mean_mae_error)\n",
        "print(\"With mean score of RMSE:\",top_mean_mae_error)\n",
        "# print(\"With mean score of MAPE:\",top_mean_mape_error)\n",
        "print(\"Cad concentration mean:\",np.mean(y_train))\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': top_y_true,\n",
        "     'lst2Title': np.reshape(np.array(top_preds),(len(top_preds)))\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters\n",
            "\n",
            "It took 0.10126898288726807 mins\n",
            "Best parameters for SVM with RBF kernal:\n",
            "{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "With mean score of MSE: 927.3482708413885\n",
            "With mean score of MAE: 16.537486641633542\n",
            "With mean score of RMSE: 16.537486641633542\n",
            "Cad concentration mean: 21.378179166666666\n",
            "correlation between y_true and y_preds: 0.3125755693823623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbCdQ2BevaVq",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest (all Features)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpJEvT3aved7",
        "colab_type": "code",
        "outputId": "ee20a4d1-9f44-4fec-ac58-9527683b5e92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "\n",
        "current=time()\n",
        "\n",
        "# gird of parameters for random forest trees \n",
        "tuned_parameters = [{'n_estimators': [10,50,100,150,200,250,300],\n",
        "                     'random_state': [30],\n",
        "                     'criterion': [\"mae\",\"mse\"],\n",
        "                     'bootstrap': [True,False]}]\n",
        "\n",
        "\n",
        "best_parameters=None\n",
        "top_mean_mse_error=10000000\n",
        "top_mean_mae_error=10000000\n",
        "top_mean_rmse_error=10000000\n",
        "top_mean_mape_error=10000000\n",
        "top_y_true=[]\n",
        "top_preds=[]\n",
        "\n",
        "print(\"# Tuning hyper-parameters\" )\n",
        "print()\n",
        "# Simulating grid search \n",
        "for g in ParameterGrid(tuned_parameters):\n",
        "    # for each possible combination in the grid\n",
        "    model= RandomForestRegressor(**g)\n",
        "    mse_scores=[]\n",
        "    rmse_scores=[]\n",
        "    mae_scores=[]\n",
        "    mape_scores=[]\n",
        "    y_true=[]\n",
        "    preds=[]\n",
        "    # doing 1 leave out cross validation\n",
        "    loo = LeaveOneOut()\n",
        "    loo.get_n_splits(X_train)\n",
        "    for train_index, test_index in loo.split(X_train):\n",
        "        X_train_cross, X_test_cross = X_train[train_index,:], X_train[test_index,:]\n",
        "        y_train_cross, y_test_cross = y_train[train_index], y_train[test_index]\n",
        "        \n",
        "        model.fit(X_train_cross,y_train_cross)\n",
        "        pred=model.predict(X_test_cross)\n",
        "        \n",
        "        preds.append(pred)\n",
        "        y_true.append(y_test_cross.values[0])\n",
        "        \n",
        "        mse=mean_squared_error(y_test_cross,pred)\n",
        "        mae=mean_absolute_error(y_test_cross,pred)\n",
        "        mape=mean_absolute_percentage_error(y_test_cross,pred)\n",
        "        \n",
        "        mse_scores.append(mse)\n",
        "        mae_scores.append(mae)\n",
        "        rmse_scores.append(np.sqrt(mse))\n",
        "        mape_scores.append(mape)\n",
        "\n",
        "    if np.mean(rmse_scores) < top_mean_rmse_error:\n",
        "        top_mean_mse_error=np.mean(mse_scores) \n",
        "        top_mean_mae_error=np.mean(mae_scores) \n",
        "        top_mean_rmse_error=np.mean(rmse_scores)\n",
        "        top_mean_mape_error=np.mean(mape_scores)\n",
        "        best_parameters=g\n",
        "        top_y_true=y_true\n",
        "        top_preds=preds\n",
        "    \n",
        "      \n",
        "print(\"It took \"+ str((time()-current)/60)+\" mins\")\n",
        "print(\"Best parameters for random forest:\")\n",
        "print(best_parameters)\n",
        "print(\"With mean score of MSE:\",top_mean_mse_error)\n",
        "print(\"With mean score of MAE:\",top_mean_mae_error)\n",
        "print(\"With mean score of RMSE:\",top_mean_rmse_error)\n",
        "# print(\"With mean score of MAPE:\",top_mean_mape_error)\n",
        "print(\"Cad concentration mean:\",np.mean(y_train))\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': top_y_true,\n",
        "     'lst2Title': np.reshape(np.array(top_preds),(len(top_preds)))\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters\n",
            "\n",
            "It took 2.217187710603078 mins\n",
            "Best parameters for random forest:\n",
            "{'bootstrap': False, 'criterion': 'mae', 'n_estimators': 150, 'random_state': 30}\n",
            "With mean score of MSE: 442.01966654953065\n",
            "With mean score of MAE: 11.206886000000006\n",
            "With mean score of RMSE: 11.206886000000006\n",
            "Cad concentration mean: 21.378179166666666\n",
            "correlation between y_true and y_preds: 0.7348613241488156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3iWWRRTq_Ei",
        "colab_type": "text"
      },
      "source": [
        "# M5 regression trees (all Features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTJzLNSwvlgs",
        "colab_type": "code",
        "outputId": "c5ab8482-5b78-472d-f773-b55e589b2e83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "#Source : https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
        "\n",
        "\n",
        "current=time()\n",
        "\n",
        "# gird of parameters for M5 regression trees \n",
        "tuned_parameters = [{'max_features': [\"auto\",\"sqrt\",\"log2\",None],\n",
        "                     'random_state': [30],\n",
        "                     'presort': [True,False],\n",
        "                     'criterion': [\"mae\",\"mse\"]}]\n",
        "\n",
        "\n",
        "best_parameters=None\n",
        "top_mean_mse_error=10000000\n",
        "top_mean_mae_error=10000000\n",
        "top_mean_rmse_error=10000000\n",
        "top_mean_mape_error=10000000\n",
        "top_y_true=[]\n",
        "top_preds=[]\n",
        "\n",
        "print(\"# Tuning hyper-parameters\" )\n",
        "print()\n",
        "# Simulating grid search \n",
        "for g in ParameterGrid(tuned_parameters):\n",
        "    # for each possible combination in the grid\n",
        "    model= DecisionTreeRegressor(**g)\n",
        "    mse_scores=[]\n",
        "    rmse_scores=[]\n",
        "    mae_scores=[]\n",
        "    mape_scores=[]\n",
        "    y_true=[]\n",
        "    preds=[]\n",
        "    # doing 1 leave out cross validation\n",
        "    loo = LeaveOneOut()\n",
        "    loo.get_n_splits(X_train)\n",
        "    for train_index, test_index in loo.split(X_train):\n",
        "        X_train_cross, X_test_cross = X_train[train_index,:], X_train[test_index,:]\n",
        "        y_train_cross, y_test_cross = y_train[train_index], y_train[test_index]\n",
        "        \n",
        "        model.fit(X_train_cross,y_train_cross)\n",
        "        pred=model.predict(X_test_cross)\n",
        "        \n",
        "        preds.append(pred)\n",
        "        y_true.append(y_test_cross.values[0])\n",
        "        \n",
        "        mse=mean_squared_error(y_test_cross,pred)\n",
        "        mae=mean_absolute_error(y_test_cross,pred)\n",
        "        mape=mean_absolute_percentage_error(y_test_cross,pred)\n",
        "        \n",
        "        mse_scores.append(mse)\n",
        "        mae_scores.append(mae)\n",
        "        rmse_scores.append(np.sqrt(mse))\n",
        "        mape_scores.append(mape)\n",
        "\n",
        "    if np.mean(rmse_scores) < top_mean_rmse_error:\n",
        "        top_mean_mse_error=np.mean(mse_scores) \n",
        "        top_mean_mae_error=np.mean(mae_scores) \n",
        "        top_mean_rmse_error=np.mean(rmse_scores)\n",
        "        top_mean_mape_error=np.mean(mape_scores)\n",
        "        best_parameters=g\n",
        "        top_y_true=y_true\n",
        "        top_preds=preds\n",
        "    \n",
        "      \n",
        "print(\"It took \"+ str((time()-current)/60)+\" mins\")\n",
        "print(\"Best parameters for M5 regression trees:\")\n",
        "print(best_parameters)\n",
        "print(\"With mean score of MSE:\",top_mean_mse_error)\n",
        "print(\"With mean score of MAE:\",top_mean_mae_error)\n",
        "print(\"With mean score of RMSE:\",top_mean_rmse_error)\n",
        "# print(\"With mean score of MAPE:\",top_mean_mape_error)\n",
        "print(\"Cad concentration mean:\",np.mean(y_train))\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': top_y_true,\n",
        "     'lst2Title': np.reshape(np.array(top_preds),(len(top_preds)))\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters\n",
            "\n",
            "It took 0.019685184955596922 mins\n",
            "Best parameters for M5 regression trees:\n",
            "{'criterion': 'mae', 'max_features': 'auto', 'presort': True, 'random_state': 30}\n",
            "With mean score of MSE: 397.1410775012501\n",
            "With mean score of MAE: 9.717062500000003\n",
            "With mean score of RMSE: 9.717062500000003\n",
            "Cad concentration mean: 21.378179166666666\n",
            "correlation between y_true and y_preds: 0.8169670697344171\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv4WmPxUv865",
        "colab_type": "text"
      },
      "source": [
        "#  GradientBoostingRegressor (GBDT ) (all Features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1eYBuLov-m0",
        "colab_type": "code",
        "outputId": "a8e8da90-402d-4d61-e868-03b460fa524b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "#Source : https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
        "\n",
        "current=time()\n",
        "\n",
        "# gird of parameters for GBDT\n",
        "tuned_parameters = [{'loss': ['ls', 'lad' ,'huber'],   \n",
        "                     'learning_rate' : [0.001,0.01,0.1],\n",
        "                     'n_estimators' : [10,40,60,100,160],\n",
        "                     'random_state': [30],\n",
        "                     'criterion': [\"friedman_mse\"],\n",
        "                     'max_features': [\"auto\",\"sqrt\",\"log2\"],\n",
        "                     'max_depth': [3,6,9,12,16]\n",
        "                    }]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "best_parameters=None\n",
        "top_mean_mse_error=10000000\n",
        "top_mean_mae_error=10000000\n",
        "top_mean_rmse_error=10000000\n",
        "top_mean_mape_error=10000000\n",
        "top_y_true=[]\n",
        "top_preds=[]\n",
        "\n",
        "print(\"# Tuning hyper-parameters\" )\n",
        "print()\n",
        "# Simulating grid search \n",
        "for g in ParameterGrid(tuned_parameters):\n",
        "    # for each possible combination in the grid\n",
        "    model= GradientBoostingRegressor(**g)\n",
        "    mse_scores=[]\n",
        "    rmse_scores=[]\n",
        "    mae_scores=[]\n",
        "    mape_scores=[]\n",
        "    y_true=[]\n",
        "    preds=[]\n",
        "    # doing 1 leave out cross validation\n",
        "    loo = LeaveOneOut()\n",
        "    loo.get_n_splits(X_train)\n",
        "    for train_index, test_index in loo.split(X_train):\n",
        "        X_train_cross, X_test_cross = X_train[train_index,:], X_train[test_index,:]\n",
        "        y_train_cross, y_test_cross = y_train[train_index], y_train[test_index]\n",
        "        \n",
        "        model.fit(X_train_cross,y_train_cross)\n",
        "        pred=model.predict(X_test_cross)\n",
        "        \n",
        "        preds.append(pred)\n",
        "        y_true.append(y_test_cross.values[0])\n",
        "        \n",
        "        mse=mean_squared_error(y_test_cross,pred)\n",
        "        mae=mean_absolute_error(y_test_cross,pred)\n",
        "        mape=mean_absolute_percentage_error(y_test_cross,pred)\n",
        "        \n",
        "        mse_scores.append(mse)\n",
        "        mae_scores.append(mae)\n",
        "        rmse_scores.append(np.sqrt(mse))\n",
        "        mape_scores.append(mape)\n",
        "\n",
        "    if np.mean(rmse_scores) < top_mean_rmse_error:\n",
        "        top_mean_mse_error=np.mean(mse_scores) \n",
        "        top_mean_mae_error=np.mean(mae_scores) \n",
        "        top_mean_rmse_error=np.mean(rmse_scores)\n",
        "        top_mean_mape_error=np.mean(mape_scores)\n",
        "        best_parameters=g\n",
        "        top_y_true=y_true\n",
        "        top_preds=preds\n",
        "    \n",
        "      \n",
        "print(\"It took \"+ str((time()-current)/60)+\" mins\")\n",
        "print(\"Best parameters for GBDT:\")\n",
        "print(best_parameters)\n",
        "print(\"With mean score of MSE:\",top_mean_mse_error)\n",
        "print(\"With mean score of MAE:\",top_mean_mae_error)\n",
        "print(\"With mean score of RMSE:\",top_mean_rmse_error)\n",
        "# print(\"With mean score of MAPE:\",top_mean_mape_error)\n",
        "print(\"Cad concentration mean:\",np.mean(y_train))\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': top_y_true,\n",
        "     'lst2Title': np.reshape(np.array(top_preds),(len(top_preds)))\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters\n",
            "\n",
            "It took 20.02120784521103 mins\n",
            "Best parameters for GBDT:\n",
            "{'criterion': 'friedman_mse', 'learning_rate': 0.1, 'loss': 'ls', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 160, 'random_state': 30}\n",
            "With mean score of MSE: 444.04811887225\n",
            "With mean score of MAE: 11.165770318059485\n",
            "With mean score of RMSE: 11.165770318059485\n",
            "Cad concentration mean: 21.378179166666666\n",
            "correlation between y_true and y_preds: 0.7341056219196949\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXO1HyAUwAgJ",
        "colab_type": "text"
      },
      "source": [
        "# CatBoostRegressor (all Features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f9J0gLjwWSO",
        "colab_type": "code",
        "outputId": "79176219-3504-4fe6-b890-312f3c4b89f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "#Source : https://catboost.ai/docs/concepts/python-reference_catboostregressor.html\n",
        "\n",
        "\n",
        "current=time()\n",
        "\n",
        "# gird of parameters for CatBoostRegressor\n",
        "tuned_parameters = [{'depth':[3,6,12], \n",
        "          #'iterations':[250,100,500],\n",
        "          'learning_rate':[0.001,0.01,0.1,0.3], \n",
        "          'l2_leaf_reg':[3,1,5,10,100],\n",
        "#           'border_count':[32,5,10,20,50,100,200],\n",
        "          #'thread_count':[4],\n",
        "           'verbose':[0]}]\n",
        "\n",
        "\n",
        "best_parameters=None\n",
        "top_mean_mse_error=10000000\n",
        "top_mean_mae_error=10000000\n",
        "top_mean_rmse_error=10000000\n",
        "top_mean_mape_error=10000000\n",
        "top_y_true=[]\n",
        "top_preds=[]\n",
        "\n",
        "counter =0\n",
        "print(\"# Tuning hyper-parameters\" )\n",
        "print()\n",
        "# Simulating grid search \n",
        "for g in ParameterGrid(tuned_parameters):\n",
        "    counter=counter+1\n",
        "    if counter %10 ==0:\n",
        "      print(counter)\n",
        "    # for each possible combination in the grid\n",
        "    model= CatBoostRegressor(**g)\n",
        "    mse_scores=[]\n",
        "    rmse_scores=[]\n",
        "    mae_scores=[]\n",
        "    mape_scores=[]\n",
        "    y_true=[]\n",
        "    preds=[]\n",
        "    # doing 1 leave out cross validation\n",
        "    loo = LeaveOneOut()\n",
        "    loo.get_n_splits(X_train)\n",
        "    for train_index, test_index in loo.split(X_train):\n",
        "        X_train_cross, X_test_cross = X_train[train_index,:], X_train[test_index,:]\n",
        "        y_train_cross, y_test_cross = y_train[train_index], y_train[test_index]\n",
        "        \n",
        "        model.fit(X_train_cross,y_train_cross)\n",
        "        pred=model.predict(X_test_cross)\n",
        "        \n",
        "        preds.append(pred)\n",
        "        y_true.append(y_test_cross.values[0])\n",
        "        \n",
        "        mse=mean_squared_error(y_test_cross,pred)\n",
        "        mae=mean_absolute_error(y_test_cross,pred)\n",
        "        mape=mean_absolute_percentage_error(y_test_cross,pred)\n",
        "        \n",
        "        mse_scores.append(mse)\n",
        "        mae_scores.append(mae)\n",
        "        rmse_scores.append(np.sqrt(mse))\n",
        "        mape_scores.append(mape)\n",
        "\n",
        "    if np.mean(rmse_scores) < top_mean_rmse_error:\n",
        "        top_mean_mse_error=np.mean(mse_scores) \n",
        "        top_mean_mae_error=np.mean(mae_scores) \n",
        "        top_mean_rmse_error=np.mean(rmse_scores)\n",
        "        top_mean_mape_error=np.mean(mape_scores)\n",
        "        best_parameters=g\n",
        "        top_y_true=y_true\n",
        "        top_preds=preds\n",
        "\n",
        "print(\"It took \"+ str((time()-current)/60)+\" mins\")\n",
        "print(\"Best parameters for CatBoostRegressor:\")\n",
        "print(best_parameters)\n",
        "print(\"With mean score of MSE:\",top_mean_mse_error)\n",
        "print(\"With mean score of MAE:\",top_mean_mae_error)\n",
        "print(\"With mean score of RMSE:\",top_mean_rmse_error)\n",
        "# print(\"With mean score of MAPE:\",top_mean_mape_error)\n",
        "print(\"Cad concentration mean:\",np.mean(y_train))\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': top_y_true,\n",
        "     'lst2Title': np.reshape(np.array(top_preds),(len(top_preds)))\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters\n",
            "\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "It took 95.9950494090716 mins\n",
            "Best parameters for CatBoostRegressor:\n",
            "{'depth': 3, 'l2_leaf_reg': 3, 'learning_rate': 0.3, 'verbose': 0}\n",
            "With mean score of MSE: 426.4333574339784\n",
            "With mean score of MAE: 11.448270151683566\n",
            "With mean score of RMSE: 11.448270151683566\n",
            "Cad concentration mean: 21.378179166666666\n",
            "correlation between y_true and y_preds: 0.7592706679256364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_trDxPprOGq",
        "colab_type": "text"
      },
      "source": [
        "# Picking the final Model for all feaures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp2XXxWO5IAL",
        "colab_type": "code",
        "outputId": "ca811ce6-90ad-49ab-f218-3a878ee9790d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "print(\"Cad concentration mean:\",np.mean(y))\n",
        "print(\"---------------------------------------------------\\n\")  \n",
        "\n",
        "# retrain all the models on the best tuned hyper-parameters\n",
        "svm_poly=SVR(**{'C': 0.1, 'degree': 3, 'gamma': 0.1, 'kernel': 'poly'})\n",
        "svm_poly.fit(X_train,y_train)\n",
        "preds=svm_poly.predict(X_test)\n",
        "#scores:\n",
        "mse=mean_squared_error(y_test,preds)\n",
        "mae=mean_absolute_error(y_test,preds)\n",
        "mape=mean_absolute_percentage_error(y_test,preds)\n",
        "r2=r2_score(y_test,preds)\n",
        "rmse=np.sqrt(mse)\n",
        "print(\"SVM with polinomial kernel, results on the testing data set:\")\n",
        "print(\"MSE:\",mse)\n",
        "print(\"RMSE: \",rmse)\n",
        "print(\"MAE:\",mae)\n",
        "print(\"MAPE: \",mape)\n",
        "print(\"R2: \",r2)\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': y_test,\n",
        "     'lst2Title': preds\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))\n",
        "print(\"---------------------------------------------------\\n\")  \n",
        "\n",
        "svm_rbf=SVR(**{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'})\n",
        "svm_rbf.fit(X_train,y_train)\n",
        "preds=svm_rbf.predict(X_test)\n",
        "#scores:\n",
        "mse=mean_squared_error(y_test,preds)\n",
        "mae=mean_absolute_error(y_test,preds)\n",
        "mape=mean_absolute_percentage_error(y_test,preds)\n",
        "r2=r2_score(y_test,preds)\n",
        "rmse=np.sqrt(mse)\n",
        "print(\"SVM with RBF kernel, results on the testing data set:\")\n",
        "print(\"MSE:\",mse)\n",
        "print(\"RMSE: \",rmse)\n",
        "print(\"MAE:\",mae)\n",
        "print(\"MAPE: \",mape)\n",
        "print(\"R2: \",r2)\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': y_test,\n",
        "     'lst2Title': preds\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))\n",
        "print(\"---------------------------------------------------\\n\") \n",
        "\n",
        "svm_linear=SVR(**{'C': 0.1, 'kernel': 'linear'})\n",
        "svm_linear.fit(X_train,y_train)\n",
        "preds=svm_linear.predict(X_test)\n",
        "#scores:\n",
        "mse=mean_squared_error(y_test,preds)\n",
        "mae=mean_absolute_error(y_test,preds)\n",
        "mape=mean_absolute_percentage_error(y_test,preds)\n",
        "r2=r2_score(y_test,preds)\n",
        "rmse=np.sqrt(mse)\n",
        "print(\"SVM with linear kernel, results on the testing data set:\")\n",
        "print(\"MSE:\",mse)\n",
        "print(\"RMSE: \",rmse)\n",
        "print(\"MAE:\",mae)\n",
        "print(\"MAPE: \",mape)\n",
        "print(\"R2: \",r2)\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': y_test,\n",
        "     'lst2Title': preds\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))\n",
        "print(\"---------------------------------------------------\\n\")\n",
        "\n",
        "randomForest=RandomForestRegressor(**{'bootstrap': False, 'criterion': 'mae', 'n_estimators': 150, 'random_state': 30})\n",
        "randomForest.fit(X_train,y_train)\n",
        "preds=randomForest.predict(X_test)\n",
        "#scores:\n",
        "mse=mean_squared_error(y_test,preds)\n",
        "mae=mean_absolute_error(y_test,preds)\n",
        "mape=mean_absolute_percentage_error(y_test,preds)\n",
        "r2=r2_score(y_test,preds)\n",
        "rmse=np.sqrt(mse)\n",
        "print(\"Random forest results on the testing data set:\")\n",
        "print(\"MSE:\",mse)\n",
        "print(\"RMSE: \",rmse)\n",
        "print(\"MAE:\",mae)\n",
        "print(\"MAPE: \",mape)\n",
        "print(\"R2: \",r2)\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': y_test,\n",
        "     'lst2Title': preds\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))\n",
        "print(\"---------------------------------------------------\\n\")\n",
        "\n",
        "\n",
        "m5_regression=DecisionTreeRegressor(**{'criterion': 'mae', 'max_features': 'auto', 'presort': True, 'random_state': 30})\n",
        "m5_regression.fit(X_train,y_train)\n",
        "preds=m5_regression.predict(X_test)\n",
        "#scores:\n",
        "mse=mean_squared_error(y_test,preds)\n",
        "mae=mean_absolute_error(y_test,preds)\n",
        "mape=mean_absolute_percentage_error(y_test,preds)\n",
        "r2=r2_score(y_test,preds)\n",
        "rmse=np.sqrt(mse)\n",
        "print(\"M5 regression trees results on the testing data set:\")\n",
        "print(\"MSE:\",mse)\n",
        "print(\"RMSE: \",rmse)\n",
        "print(\"MAE:\",mae)\n",
        "print(\"MAPE: \",mape)\n",
        "print(\"R2: \",r2)\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': y_test,\n",
        "     'lst2Title': preds\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))\n",
        "print(\"---------------------------------------------------\\n\")\n",
        "\n",
        "# to add optimal paraeters: \n",
        "\n",
        "GBDT=GradientBoostingRegressor(**{'criterion': 'friedman_mse', 'learning_rate': 0.1, 'loss': 'ls', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 160, 'random_state': 30})\n",
        "GBDT.fit(X_train,y_train)\n",
        "preds=GBDT.predict(X_test)\n",
        "#scores:\n",
        "mse=mean_squared_error(y_test,preds)\n",
        "mae=mean_absolute_error(y_test,preds)\n",
        "mape=mean_absolute_percentage_error(y_test,preds)\n",
        "r2=r2_score(y_test,preds)\n",
        "rmse=np.sqrt(mse)\n",
        "print(\"GBDT results on the testing data set:\")\n",
        "print(\"MSE:\",mse)\n",
        "print(\"RMSE: \",rmse)\n",
        "print(\"MAE:\",mae)\n",
        "print(\"MAPE: \",mape)\n",
        "print(\"R2: \",r2)\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': y_test,\n",
        "     'lst2Title': preds\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))\n",
        "print(\"---------------------------------------------------\\n\")\n",
        "\n",
        "catBostReg=CatBoostRegressor(**{'depth': 3, 'l2_leaf_reg': 3, 'learning_rate': 0.3, 'verbose': 0})\n",
        "catBostReg.fit(X_train,y_train)\n",
        "preds=catBostReg.predict(X_test)\n",
        "#scores:\n",
        "mse=mean_squared_error(y_test,preds)\n",
        "mae=mean_absolute_error(y_test,preds)\n",
        "mape=mean_absolute_percentage_error(y_test,preds)\n",
        "r2=r2_score(y_test,preds)\n",
        "rmse=np.sqrt(mse)\n",
        "print(\"CatBoostRegressor results on the testing data set:\")\n",
        "print(\"MSE:\",mse)\n",
        "print(\"RMSE: \",rmse)\n",
        "print(\"MAE:\",mae)\n",
        "print(\"MAPE: \",mape)\n",
        "print(\"R2: \",r2)\n",
        "df=pd.DataFrame(\n",
        "    {'lst1Title': y_test,\n",
        "     'lst2Title': preds\n",
        "    })\n",
        "print(\"correlation between y_true and y_preds:\",df[\"lst1Title\"].corr(df[\"lst2Title\"]))\n",
        "print(\"---------------------------------------------------\\n\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cad concentration mean: 24.001398387096778\n",
            "---------------------------------------------------\n",
            "\n",
            "SVM with polinomial kernel, results on the testing data set:\n",
            "MSE: 1530.9998520916963\n",
            "RMSE:  39.12799320297038\n",
            "MAE: 24.421083039918408\n",
            "MAPE:  50.02881043784514\n",
            "R2:  -0.34024218506314785\n",
            "correlation between y_true and y_preds: 0.09342599216881639\n",
            "---------------------------------------------------\n",
            "\n",
            "SVM with RBF kernel, results on the testing data set:\n",
            "MSE: 1457.4243440814873\n",
            "RMSE:  38.17622747314731\n",
            "MAE: 22.383201133833115\n",
            "MAPE:  49.14535390753843\n",
            "R2:  -0.27583394917206583\n",
            "correlation between y_true and y_preds: 0.34369926398228245\n",
            "---------------------------------------------------\n",
            "\n",
            "SVM with linear kernel, results on the testing data set:\n",
            "MSE: 1442.0554564161607\n",
            "RMSE:  37.97440528061185\n",
            "MAE: 23.115969264792593\n",
            "MAPE:  59.85447930040693\n",
            "R2:  -0.2623799755753826\n",
            "correlation between y_true and y_preds: 0.286706379918632\n",
            "---------------------------------------------------\n",
            "\n",
            "Random forest results on the testing data set:\n",
            "MSE: 1865.6469730150313\n",
            "RMSE:  43.19313571639632\n",
            "MAE: 26.95912219047619\n",
            "MAPE:  139.6177362888302\n",
            "R2:  -0.6331933489438086\n",
            "correlation between y_true and y_preds: 0.39780836889184457\n",
            "---------------------------------------------------\n",
            "\n",
            "M5 regression trees results on the testing data set:\n",
            "MSE: 323.6954149832142\n",
            "RMSE:  17.991537315727477\n",
            "MAE: 14.271207142857142\n",
            "MAPE:  90.79730192658793\n",
            "R2:  0.7166359946545298\n",
            "correlation between y_true and y_preds: 0.8632127086305599\n",
            "---------------------------------------------------\n",
            "\n",
            "GBDT results on the testing data set:\n",
            "MSE: 1548.6066714512106\n",
            "RMSE:  39.35234010133591\n",
            "MAE: 24.563429005376925\n",
            "MAPE:  109.19081094688343\n",
            "R2:  -0.355655251248731\n",
            "correlation between y_true and y_preds: 0.47692621089531423\n",
            "---------------------------------------------------\n",
            "\n",
            "CatBoostRegressor results on the testing data set:\n",
            "MSE: 1730.5510199966225\n",
            "RMSE:  41.59989206712708\n",
            "MAE: 27.047666486271247\n",
            "MAPE:  93.80670913731544\n",
            "R2:  -0.5149299180106119\n",
            "correlation between y_true and y_preds: 0.21837640673580114\n",
            "---------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}